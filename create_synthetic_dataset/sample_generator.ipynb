{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Danish Identity Phrase Templates Test Set\n",
    "\n",
    "The goal of this notebook is to create a synthetic dataset (IPTTS) that can be used to measure the unintended bias in toxicity classifiers. Samples are created from selected verbs, adjectives and identity terms. \n",
    "\n",
    "Inspired by Dixon et al. (2018): https://doi.org/10.1145/3278721.3278729 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare functions, data etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import lemmy\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def read_content(filename:str) -> List[str]:\n",
    "    \"\"\"Opens file and returns its contents as a list split by newlines.\n",
    "\n",
    "    Args:\n",
    "        filename (str): name of file.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: list of the lines in the file.\n",
    "    \"\"\"\n",
    "    f = open(filename)\n",
    "    contents = f.read().split(\"\\n\")\n",
    "    f.close()\n",
    "    return contents\n",
    "\n",
    "def get_word_pos(wordtype:str, wordlist:List[str]) -> int:\n",
    "    \"\"\"Returns the position of the word to be inserted in list of words.\n",
    "\n",
    "    Args:\n",
    "        wordtype (str): either verb, identity, article or adjective.\n",
    "        wordlist (List[str]): the sentence template as a list of words.\n",
    "\n",
    "    Returns:\n",
    "        int: the index of the word to be inserted.\n",
    "    \"\"\"\n",
    "    for i, word in enumerate(wordlist):\n",
    "        if wordtype.upper() == \"VERB\":\n",
    "            if \"VERB\" in word:\n",
    "                return i\n",
    "        elif wordtype.upper() == \"IDENTITY\":\n",
    "            if \"IDENTITY\" in word:\n",
    "                return i\n",
    "        elif wordtype.upper() == \"ARTICLE\":\n",
    "            if \"ARTICLE\" in word:\n",
    "                return i\n",
    "        elif wordtype.upper() == \"ADJECTIVE\":\n",
    "            if \"ADJECTIVE\" in word:\n",
    "                return i\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "def determine_verb_list(verbtype:str, polarity:str) -> List[str]:\n",
    "    \"\"\"Determines which verb list to use based on the verbtype specified in the sample\n",
    "    and returns its contents.\n",
    "\n",
    "    Args:\n",
    "        verbtype (str): the options are \"VERB_PRS\" (present tense), \"VERB_IMP\" (imperative), or \"VERB_PASS\" (passive).\n",
    "        polarity (str): either \"neg\" (negative) or \"pos\" (positive).\n",
    "\n",
    "    Returns:\n",
    "        List[str]: a list of either negative or positive verbs of the given type. \n",
    "    \"\"\"\n",
    "    if polarity == \"neg\":\n",
    "        if verbtype == \"VERB_PRS\":\n",
    "            return read_content(\"verbs/neg_prs.txt\") # present tense\n",
    "        elif verbtype == \"VERB_IMP\":\n",
    "            return read_content(\"verbs/neg_imp.txt\") # imperative\n",
    "        elif verbtype == \"VERB_PASS\":\n",
    "            return read_content(\"verbs/neg_pass.txt\") # passive\n",
    "    elif polarity == \"pos\":\n",
    "        if verbtype == \"VERB_PRS\":\n",
    "            return read_content(\"verbs/pos_prs.txt\") # present tense\n",
    "        elif verbtype == \"VERB_IMP\":\n",
    "            return read_content(\"verbs/pos_imp.txt\") # imperative\n",
    "        elif verbtype == \"VERB_PASS\":\n",
    "            return read_content(\"verbs/pos_pass.txt\") # passive\n",
    "    return None\n",
    "    \n",
    "def determine_identity_lists(identitytype:str) -> Dict[str, List[str]]:\n",
    "    \"\"\"Determines which type of identity list to use based on the type specified in the sample\n",
    "    and returns the contents for each identity group as a dictionary.\n",
    "\n",
    "    Args:\n",
    "        identitytype (str): either \"IDENTITY_PL\" (plural) or \"IDENTITY_SG\" (singular).\n",
    "\n",
    "    Returns:\n",
    "        Dict[str: List[str]]: a dictionary of three lists of either singular or plural \n",
    "        identity words (female, male, and non-conform gender identities). \n",
    "    \"\"\"    \n",
    "    identitytype = re.sub(r'[^A-z]','', identitytype) # remove punctuation from identity type\n",
    "    if identitytype == \"IDENTITY_PL\":\n",
    "        return {\n",
    "            \"F\": read_content(\"identities/female_pl.txt\"), \n",
    "            \"M\": read_content(\"identities/male_pl.txt\"), \n",
    "            \"Q\": read_content(\"identities/queer_pl.txt\")\n",
    "            }\n",
    "    elif identitytype == \"IDENTITY_SG\":\n",
    "        return {\n",
    "            \"F\": read_content(\"identities/female_sg.txt\"), \n",
    "            \"M\": read_content(\"identities/male_sg.txt\"), \n",
    "            \"Q\": read_content(\"identities/queer_sg.txt\")\n",
    "            }    \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "def generate_samples(templates:List[str], polarity:str=None) -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate samples from templates by slotting in identities and if necessary, verbs and adjectives. Returns a list of the generated samples.\n",
    "    \n",
    "    Args:\n",
    "        templates (List[str]): list of templates as strings.\n",
    "        polarity (str): allows the values \"pos\" and \"neg\" that specifies whether the sentiment of the verbs/adjectives is positive or negative. \n",
    "\n",
    "    Returns:\n",
    "        List[str]: list of generated samples as strings.\n",
    "    \"\"\"\n",
    "    generated_samples = []\n",
    "    samples_groups = []\n",
    "    samples_identity_terms = []\n",
    "\n",
    "    # go through templates\n",
    "    for template in templates:\n",
    "\n",
    "        sample = template.split()\n",
    "        \n",
    "        # get identity position and list\n",
    "        IDENTITY_POS = get_word_pos(\"identity\", sample)\n",
    "        IDENTITY_LIST_DICT = determine_identity_lists(sample[IDENTITY_POS])\n",
    "        IS_PLURAL = sample[IDENTITY_POS].endswith(\"_PL\") # check for plurality\n",
    "\n",
    "        # get verb position and list (if relevant)\n",
    "        VERB_POS = get_word_pos(\"verb\", sample)\n",
    "        if VERB_POS is not None: # i.e. if there's a verb slot in the template\n",
    "            VERB_LIST = determine_verb_list(sample[VERB_POS], polarity)\n",
    "        \n",
    "        # get article position\n",
    "        ART_POS = get_word_pos(\"article\", sample)\n",
    "        \n",
    "        # get adjective position\n",
    "        ADJ_POS = get_word_pos(\"adjective\", sample)\n",
    "\n",
    "        # create one version of this template per identity\n",
    "        for identity_group in IDENTITY_LIST_DICT: # loops through keys (F = female, M = male, Q = queer/non-conform gender identities)\n",
    "            for identity in IDENTITY_LIST_DICT[identity_group]: # loops through identity terms in list for this group, e.g. female\n",
    "                identity_copy = identity\n",
    "                \n",
    "                # if the article has its own position in the sentence, move it here\n",
    "                # otherwise it is kept as part of the NP that the identities consist of\n",
    "                if ART_POS is not None:            \n",
    "                    # split the identity phrase into article and the rest\n",
    "                    words = identity_copy.split()\n",
    "                    article = words[0]\n",
    "                    identity_copy = ' '.join(words[1:])\n",
    "\n",
    "                    # insert article at article position\n",
    "                    sample[ART_POS] = article\n",
    "                else:\n",
    "                    article = None\n",
    "                \n",
    "                # insert noun at IDENTITY position\n",
    "                sample[IDENTITY_POS] = identity_copy\n",
    "                \n",
    "                # then create one version of this per verb, if necessary\n",
    "                if VERB_POS is not None:\n",
    "                    for verb in VERB_LIST:\n",
    "                        sample[VERB_POS] = verb\n",
    "                        generated_samples.append(' '.join(sample)) # SAMPLE WITH VERB\n",
    "                        samples_groups.append(identity_group) # store identity group (dict key)\n",
    "                        samples_identity_terms.append(identity) # store identity term\n",
    "\n",
    "                # then create one version of this per adjective, if necessary\n",
    "                elif ADJ_POS is not None:\n",
    "                    for adj in read_content(f\"adjectives/{polarity}.txt\"):\n",
    "                        conjugations = adj.split(\",\") # conjugations in the order: standard, neuter, plural\n",
    "                \n",
    "                        # if neuter article or noun, use neuter conjugation\n",
    "                        if article == \"et\" or sample[0].lower() == \"det\": \n",
    "                            adj = conjugations[1].strip()\n",
    "                \n",
    "                        # if plural noun phrase, use plural adjective\n",
    "                        elif IS_PLURAL:\n",
    "                            adj = conjugations[2].strip()\n",
    "                        \n",
    "                        # else use standard version            \n",
    "                        else:\n",
    "                            adj = conjugations[0].strip()\n",
    "                            \n",
    "                        # insert adjective at ADJ position and add sample to list\n",
    "                        sample[ADJ_POS] = adj \n",
    "                        generated_samples.append(' '.join(sample)) # SAMPLE WITH ADJECTIVE\n",
    "                        samples_groups.append(identity_group) # store identity group (dict key)\n",
    "                        samples_identity_terms.append(identity) # store identity term\n",
    "                        \n",
    "                else: # i.e. if no verb or adjective is needed, create sample\n",
    "                    generated_samples.append(' '.join(sample)) # SAMPLE WITHOUT VERB OR ADJECTIVE\n",
    "                    samples_groups.append(identity_group) # store identity group (dict key)  \n",
    "                    samples_identity_terms.append(identity) # store identity term   \n",
    "\n",
    "    print(len(generated_samples), \"samples created\")\n",
    "    \n",
    "    return generated_samples, samples_groups, samples_identity_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 verbs\n",
      "45 identities\n",
      "50 adjectives\n"
     ]
    }
   ],
   "source": [
    "print(len(read_content(\"verbs/neg_imp.txt\"))*2, \"verbs\")\n",
    "print(len(read_content(\"identities/female_sg.txt\"))*3, \"identities\")\n",
    "print(len(read_content(\"adjectives/pos.txt\"))*2, \"adjectives\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create samples for templates that are ALWAYS toxic such as \"I hate all [identity]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 templates:\n",
      "['IDENTITY_PL er klamme og generelt bare nederen', 'Jeg er IDENTITY_SG, og jeg hader dig og synes, du er træls', 'Jeg hader alle IDENTITY_PL']\n",
      "\n",
      "Should get 135 samples (3 templates * 45 identities)\n"
     ]
    }
   ],
   "source": [
    "# open templates that are always toxic\n",
    "templates = read_content(\"templates/always_neg.txt\")\n",
    "print(len(templates), \"templates:\")\n",
    "print(templates)\n",
    "print(f\"\\nShould get {(3*45):,} samples (3 templates * 45 identities)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 samples created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>group</th>\n",
       "      <th>identity_term</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kvinder er klamme og generelt bare nederen</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>piger er klamme og generelt bare nederen</td>\n",
       "      <td>F</td>\n",
       "      <td>piger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>damer er klamme og generelt bare nederen</td>\n",
       "      <td>F</td>\n",
       "      <td>damer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>koner er klamme og generelt bare nederen</td>\n",
       "      <td>F</td>\n",
       "      <td>koner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kvindfolk er klamme og generelt bare nederen</td>\n",
       "      <td>F</td>\n",
       "      <td>kvindfolk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text group identity_term  toxic\n",
       "0    kvinder er klamme og generelt bare nederen     F       kvinder      1\n",
       "1      piger er klamme og generelt bare nederen     F         piger      1\n",
       "2      damer er klamme og generelt bare nederen     F         damer      1\n",
       "3      koner er klamme og generelt bare nederen     F         koner      1\n",
       "4  kvindfolk er klamme og generelt bare nederen     F     kvindfolk      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate samples using these templates\n",
    "\n",
    "generated_samples, samples_groups, samples_identity_terms = generate_samples(templates)\n",
    "df1 = pd.DataFrame(list(zip(generated_samples, samples_groups, samples_identity_terms)), columns=['text', 'group', 'identity_term'])\n",
    "df1['toxic'] = 1 # these sentences are always non-toxic/neutral\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create samples for templates that are ALWAYS non-toxic such as \"I am a/an [identity]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 templates:\n",
      "['Jeg er IDENTITY_SG, spørg mig om alt', 'IDENTITY_PL er ligesom alle andre', 'Jeg er IDENTITY_SG']\n",
      "\n",
      "Should get 135 samples (3 templates * 45 identities)\n"
     ]
    }
   ],
   "source": [
    "# open templates that are always non-toxic/neutral\n",
    "templates = read_content(\"templates/always_neu.txt\")\n",
    "print(len(templates), \"templates:\")\n",
    "print(templates)\n",
    "print(f\"\\nShould get {(3*45):,} samples (3 templates * 45 identities)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 samples created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>group</th>\n",
       "      <th>identity_term</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jeg er en kvinde spørg mig om alt</td>\n",
       "      <td>F</td>\n",
       "      <td>en kvinde</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jeg er en pige spørg mig om alt</td>\n",
       "      <td>F</td>\n",
       "      <td>en pige</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jeg er en dame spørg mig om alt</td>\n",
       "      <td>F</td>\n",
       "      <td>en dame</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jeg er en kone spørg mig om alt</td>\n",
       "      <td>F</td>\n",
       "      <td>en kone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jeg er et kvindfolk spørg mig om alt</td>\n",
       "      <td>F</td>\n",
       "      <td>et kvindfolk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text group identity_term  toxic\n",
       "0     Jeg er en kvinde spørg mig om alt     F     en kvinde      0\n",
       "1       Jeg er en pige spørg mig om alt     F       en pige      0\n",
       "2       Jeg er en dame spørg mig om alt     F       en dame      0\n",
       "3       Jeg er en kone spørg mig om alt     F       en kone      0\n",
       "4  Jeg er et kvindfolk spørg mig om alt     F  et kvindfolk      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate samples using these templates\n",
    "\n",
    "generated_samples, samples_groups, samples_identity_terms = generate_samples(templates)\n",
    "df2 = pd.DataFrame(list(zip(generated_samples, samples_groups, samples_identity_terms)), columns=['text', 'group', 'identity_term'])\n",
    "df2['toxic'] = 0 # these sentences are always non-toxic/neutral\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create samples for templates whose toxicity depend on the polarity of the verb such as \"I [verb] [identities]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 templates:\n",
      "['VERB_IMP IDENTITY_PL', 'Jeg VERB_PRS IDENTITY_PL', 'IDENTITY_PL bør VERB_PASS']\n",
      "\n",
      "Should get 3,510 samples (3 templates * 45 identities * 26 verbs)\n",
      "Half should be negative/toxic, half positive/non-toxic\n"
     ]
    }
   ],
   "source": [
    "# open templates that depend on the verb\n",
    "templates = read_content(\"templates/verb_dependent.txt\")\n",
    "print(len(templates), \"templates:\")\n",
    "print(templates)\n",
    "print(f\"\\nShould get {(3*45*26):,} samples (3 templates * 45 identities * 26 verbs)\")\n",
    "print(\"Half should be negative/toxic, half positive/non-toxic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1755 samples created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>group</th>\n",
       "      <th>identity_term</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afsky kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dræb kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eliminer kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>had kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>henret kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text group identity_term  toxic\n",
       "0     afsky kvinder     F       kvinder      1\n",
       "1      dræb kvinder     F       kvinder      1\n",
       "2  eliminer kvinder     F       kvinder      1\n",
       "3       had kvinder     F       kvinder      1\n",
       "4    henret kvinder     F       kvinder      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate samples using these templates\n",
    "\n",
    "# toxic/negative samples\n",
    "generated_samples, samples_groups, samples_identity_terms = generate_samples(templates, \"neg\")\n",
    "df3 = pd.DataFrame(list(zip(generated_samples, samples_groups, samples_identity_terms)), columns=['text', 'group', 'identity_term'])\n",
    "df3['toxic'] = 1 \n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1755 samples created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>group</th>\n",
       "      <th>identity_term</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beundr kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eftertragt kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elsk kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fejr kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hædr kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 text group identity_term  toxic\n",
       "0      beundr kvinder     F       kvinder      0\n",
       "1  eftertragt kvinder     F       kvinder      0\n",
       "2        elsk kvinder     F       kvinder      0\n",
       "3        fejr kvinder     F       kvinder      0\n",
       "4        hædr kvinder     F       kvinder      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non-toxic/positive samples\n",
    "generated_samples, samples_groups, samples_identity_terms = generate_samples(templates, \"pos\")\n",
    "df4 = pd.DataFrame(list(zip(generated_samples, samples_groups, samples_identity_terms)), columns=['text', 'group', 'identity_term'])\n",
    "df4['toxic'] = 0 \n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create samples for templates whose toxicity depend on the polarity of the adjective such as \"[identities] are [adjective]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 templates:\n",
      "['ADJECTIVE IDENTITY_PL', 'Du er ARTICLE ADJECTIVE IDENTITY_SG', 'Det er ADJECTIVE at være IDENTITY_SG', 'IDENTITY_PL er ADJECTIVE']\n",
      "\n",
      "Should get 9,000 samples (4 templates * 45 identities * 50 adjectives)\n",
      "Half should be negative/toxic, half positive/non-toxic\n"
     ]
    }
   ],
   "source": [
    "# open templates that depend on the adjective\n",
    "templates = read_content(\"templates/adjective_dependent.txt\")\n",
    "print(len(templates), \"templates:\")\n",
    "print(templates)\n",
    "print(f\"\\nShould get {(4*45*50):,} samples (4 templates * 45 identities * 50 adjectives)\")\n",
    "print(\"Half should be negative/toxic, half positive/non-toxic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500 samples created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>group</th>\n",
       "      <th>identity_term</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dårlige kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gale kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kriminelle kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>onde kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lede kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 text group identity_term  toxic\n",
       "0     dårlige kvinder     F       kvinder      1\n",
       "1        gale kvinder     F       kvinder      1\n",
       "2  kriminelle kvinder     F       kvinder      1\n",
       "3        onde kvinder     F       kvinder      1\n",
       "4        lede kvinder     F       kvinder      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate samples using these templates\n",
    "\n",
    "# toxic/negative samples\n",
    "generated_samples, samples_groups, samples_identity_terms = generate_samples(templates, \"neg\")\n",
    "df5 = pd.DataFrame(list(zip(generated_samples, samples_groups, samples_identity_terms)), columns=['text', 'group', 'identity_term'])\n",
    "df5['toxic'] = 1 \n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500 samples created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>group</th>\n",
       "      <th>identity_term</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sjove kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glade kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>super kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fantastiske kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spændende kvinder</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  text group identity_term  toxic\n",
       "0        sjove kvinder     F       kvinder      0\n",
       "1        glade kvinder     F       kvinder      0\n",
       "2        super kvinder     F       kvinder      0\n",
       "3  fantastiske kvinder     F       kvinder      0\n",
       "4    spændende kvinder     F       kvinder      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non-toxic/positive samples\n",
    "generated_samples, samples_groups, samples_identity_terms = generate_samples(templates, \"pos\")\n",
    "df6 = pd.DataFrame(list(zip(generated_samples, samples_groups, samples_identity_terms)), columns=['text', 'group', 'identity_term'])\n",
    "df6['toxic'] = 0 \n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all temporary dataframes into a single one and save as xlsx-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in each df:\n",
      "\n",
      "Always toxic (no verb/adj)    :    135\n",
      "Always non-toxic (no verb/adj):    135\n",
      "Toxic because of verb         :  1,755\n",
      "Non-toxic because of verb     :  1,755\n",
      "Toxic because of adjective    :  4,500\n",
      "Non-toxic because of adjective:  4,500\n",
      "\n",
      "Total                         = 12,780 samples\n"
     ]
    }
   ],
   "source": [
    "# Overview of dataset \n",
    "print(\"Number of samples in each df:\\n\")\n",
    "print(f\"Always toxic (no verb/adj)    :    {len(df1)}\")\n",
    "print(f\"Always non-toxic (no verb/adj):    {len(df2)}\")\n",
    "print(f\"Toxic because of verb         :  {len(df3):,}\")\n",
    "print(f\"Non-toxic because of verb     :  {len(df4):,}\")\n",
    "print(f\"Toxic because of adjective    :  {len(df5):,}\")\n",
    "print(f\"Non-toxic because of adjective:  {len(df6):,}\")\n",
    "print()\n",
    "print(f\"Total                         = {sum([len(df1), len(df2), len(df3), len(df4), len(df5), len(df6)]):,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>group</th>\n",
       "      <th>identity_term</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kvinder er klamme og generelt bare nederen</td>\n",
       "      <td>F</td>\n",
       "      <td>kvinder</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>piger er klamme og generelt bare nederen</td>\n",
       "      <td>F</td>\n",
       "      <td>piger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>damer er klamme og generelt bare nederen</td>\n",
       "      <td>F</td>\n",
       "      <td>damer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>koner er klamme og generelt bare nederen</td>\n",
       "      <td>F</td>\n",
       "      <td>koner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kvindfolk er klamme og generelt bare nederen</td>\n",
       "      <td>F</td>\n",
       "      <td>kvindfolk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>genderqueer personer er suveræne</td>\n",
       "      <td>Q</td>\n",
       "      <td>genderqueer personer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>genderqueer personer er herlige</td>\n",
       "      <td>Q</td>\n",
       "      <td>genderqueer personer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>genderqueer personer er fornemme</td>\n",
       "      <td>Q</td>\n",
       "      <td>genderqueer personer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>genderqueer personer er ekstraordinære</td>\n",
       "      <td>Q</td>\n",
       "      <td>genderqueer personer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>genderqueer personer er loyale</td>\n",
       "      <td>Q</td>\n",
       "      <td>genderqueer personer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12780 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text group  \\\n",
       "0       kvinder er klamme og generelt bare nederen     F   \n",
       "1         piger er klamme og generelt bare nederen     F   \n",
       "2         damer er klamme og generelt bare nederen     F   \n",
       "3         koner er klamme og generelt bare nederen     F   \n",
       "4     kvindfolk er klamme og generelt bare nederen     F   \n",
       "...                                            ...   ...   \n",
       "4495              genderqueer personer er suveræne     Q   \n",
       "4496               genderqueer personer er herlige     Q   \n",
       "4497              genderqueer personer er fornemme     Q   \n",
       "4498        genderqueer personer er ekstraordinære     Q   \n",
       "4499                genderqueer personer er loyale     Q   \n",
       "\n",
       "             identity_term  toxic  \n",
       "0                  kvinder      1  \n",
       "1                    piger      1  \n",
       "2                    damer      1  \n",
       "3                    koner      1  \n",
       "4                kvindfolk      1  \n",
       "...                    ...    ...  \n",
       "4495  genderqueer personer      0  \n",
       "4496  genderqueer personer      0  \n",
       "4497  genderqueer personer      0  \n",
       "4498  genderqueer personer      0  \n",
       "4499  genderqueer personer      0  \n",
       "\n",
       "[12780 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate into one df\n",
    "synthetic_data = pd.concat([df1, df2, df3, df4, df5, df6])\n",
    "synthetic_data.drop_duplicates() # ensure that theres no duplicates\n",
    "synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words before lemmatization: 90\n",
      "Number of unique words after lemmatization: 45\n"
     ]
    }
   ],
   "source": [
    "# create column with lemmas, i.e. plural == singular\n",
    "def standardize_words(text:str) -> str:\n",
    "    \"\"\"Remove the article and 'person'. Change tempus of words that cause the lemmatizer issues.\n",
    "\n",
    "    Args:\n",
    "        text (str): text before standardization.\n",
    "\n",
    "    Returns:\n",
    "        str: text after standardization.\n",
    "    \"\"\"\n",
    "    text = text.removeprefix(\"en\")\n",
    "    text = text.removeprefix(\"et\")\n",
    "    text = text.removesuffix(\"person\")\n",
    "    text = text.removesuffix(\"personer\")\n",
    "    text = text.strip()\n",
    "    if text == \"fyre\":\n",
    "        return \"fyr\"\n",
    "    elif text == \"mand\":\n",
    "        return \"mænd\"\n",
    "    elif text == \"mor\":\n",
    "        return \"mødre\"\n",
    "    elif text == \"tøs\":\n",
    "        return \"tøser\"\n",
    "    return text\n",
    "\n",
    "lemmatizer = lemmy.load(\"da\")\n",
    "synthetic_data['identity_lemma'] = synthetic_data['identity_term'].apply(lambda text: standardize_words(text))\n",
    "synthetic_data['identity_lemma'] = synthetic_data['identity_lemma'].apply(lambda text: lemmatizer.lemmatize(\"\", text.strip())[0]) \n",
    "\n",
    "print(\"Number of unique words before lemmatization:\", synthetic_data['identity_term'].nunique())\n",
    "print(\"Number of unique words after lemmatization:\", synthetic_data['identity_lemma'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data set\n",
    "data_path = os.getcwd().removesuffix(\"\\\\create_synthetic_dataset\")+\"\\\\toxicity_detection\\\\data\\\\synthetic_data.xlsx\"\n",
    "synthetic_data.to_excel(data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "1    6390\n",
      "0    6390\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# how many samples are toxic and not?\n",
    "print(synthetic_data['toxic'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group\n",
      "F    4260\n",
      "M    4260\n",
      "Q    4260\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# how many samples are in each identity group?\n",
    "print(synthetic_data['group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words before lemmatization: 90\n",
      "Number of unique words after lemmatization: 45\n"
     ]
    }
   ],
   "source": [
    "# create small version of dataset \n",
    "synthetic_data_small = pd.concat([df1, df2, df3, df4])\n",
    "synthetic_data_small.drop_duplicates()\n",
    "lemmatizer = lemmy.load(\"da\")\n",
    "synthetic_data_small['identity_lemma'] = synthetic_data_small['identity_term'].apply(lambda text: standardize_words(text))\n",
    "synthetic_data_small['identity_lemma'] = synthetic_data_small['identity_lemma'].apply(lambda text: lemmatizer.lemmatize(\"\", text.strip())[0]) \n",
    "print(\"Number of unique words before lemmatization:\", synthetic_data_small['identity_term'].nunique())\n",
    "print(\"Number of unique words after lemmatization:\", synthetic_data_small['identity_lemma'].nunique())\n",
    "data_path = os.getcwd().removesuffix(\"\\\\create_synthetic_dataset\")+\"\\\\toxicity_detection\\\\data\\\\synthetic_data_small.xlsx\"\n",
    "synthetic_data_small.to_excel(data_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
