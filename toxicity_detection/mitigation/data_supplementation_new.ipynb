{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Supplementation (suppl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method\n",
    "1.\tIdentify identity terms with the most disproportionate data distributions \n",
    "    1. Stem/lemmatize dataset\n",
    "    2. For each lemma in the synthetic test set:\n",
    "        1. Check distribution across labels in dataset, i.e. difference between frequency in toxic comments and overall\n",
    "        2.\tAlso check length differences!\n",
    "    3. What does this mean exactly? \n",
    "        1.\t“Identity terms affected by the false positive bias are disproportionately used in toxic comments in our training data. For example, the word ‘gay’ appears in 3% of toxic comments but only 0.5% of comments overall.”\n",
    "        2.\tFrequency of identity terms in toxic comments and overall: \n",
    "2.\tAdd additional non-toxic examples that contain the identity terms that appear disproportionately across labels in the original dataset\n",
    "    1.\tUse wiki data – assumed to be non-toxic\n",
    "    2.\tAdd enough so that the balance is in line with the prior distribution for the overall dataset\n",
    "        1.\tE.g. until % “gay” in toxic comment is close to 0.50% as in overall data.\n",
    "3.\tMaybe consider different lengths as CNNs could be sensitive to this\n",
    "    1.\t“toxic comments tend to be shorter” (Dixon et al. 2018)\n",
    "4.\tSupposed to reduce false positives. Could also do the opposite? But more difficult to find toxic comments unless we take them from places that are supposedly toxic (e.g. “roast me”)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\love2\\anaconda3\\envs\\thesis2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# set cwd\n",
    "import os\n",
    "os.chdir(\"g:\\\\My Drive\\\\ITC, 5th semester (Thesis)\\\\Code\\\\Github_code\\\\toxicity_detection\")\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "# from random import choice, choices\n",
    "# from collections import \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from string import punctuation\n",
    "# # import spacy\n",
    "from spacy import displacy\n",
    "from tqdm import tqdm\n",
    "from utils import load_dkhate\n",
    "from typing import List\n",
    "import pickle\n",
    "import dacy\n",
    "import utils\n",
    "import nltk\n",
    "# import re\n",
    "# import string\n",
    "from wiki_scraper import scrape_wiki_text\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text:str) -> str:\n",
    "    \"\"\"Returns a lemmatized version of the text or itself if the string is empty.\"\"\"\n",
    "    if len(text) > 0:\n",
    "        doc = nlp(text)\n",
    "        lemmas = [token.lemma_ for token in doc]\n",
    "        lemmatized_text = \" \".join(lemmas)\n",
    "        return lemmatized_text\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def occurs_in_string(target:str, text:str) -> bool:\n",
    "    \"\"\"Checks whether a word occurs in a text.\"\"\"\n",
    "    for word in text.split():\n",
    "        if word == target:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DaCy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load daCy model (medium works fine)\n",
    "nlp = dacy.load(\"da_dacy_medium_trf-0.2.0\") # takes around 4 minutes the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token     \tLemma\t\tPOS-tag\t\tEntity type\n",
      "Mit       :\tMit       \tDET\t\t\n",
      "navn      :\tnavn      \tNOUN\t\t\n",
      "er        :\tvære      \tAUX\t\t\n",
      "Maja      :\tMaja      \tPROPN\t\tPER\n",
      ".         :\t.         \tPUNCT\t\t\n",
      "Jeg       :\tjeg       \tPRON\t\t\n",
      "bor       :\tbo        \tVERB\t\t\n",
      "på        :\tpå        \tADP\t\t\n",
      "Bispebjerg:\tBispebjerg\tPROPN\t\tLOC\n",
      ",         :\t,         \tPUNCT\t\t\n",
      "men       :\tmen       \tCCONJ\t\t\n",
      "er        :\tvære      \tVERB\t\t\n",
      "fra       :\tfra       \tADP\t\t\n",
      "Næstved   :\tNæstved   \tPROPN\t\tLOC\n",
      ".         :\t.         \tPUNCT\t\t\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mit navn er \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Maja\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER\n",
       " <a style=\"text-decoration: none; color: inherit; font-weight: normal\" href=\"#\">Q18184581</a>\n",
       "</span>\n",
       "</mark>\n",
       ". Jeg bor på \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bispebjerg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC\n",
       " <a style=\"text-decoration: none; color: inherit; font-weight: normal\" href=\"#\">NIL</a>\n",
       "</span>\n",
       "</mark>\n",
       ", men er fra \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Næstved\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC\n",
       " <a style=\"text-decoration: none; color: inherit; font-weight: normal\" href=\"#\">Q21178</a>\n",
       "</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test that it works as expected \n",
    "doc = nlp(\"Mit navn er Maja. Jeg bor på Bispebjerg, men er fra Næstved.\") \n",
    "print(\"Token     \\tLemma\\t\\tPOS-tag\\t\\tEntity type\")\n",
    "for tok in doc: \n",
    "    print(f\"{str(tok).ljust(10)}:\\t{str(tok.lemma_).ljust(10)}\\t{tok.pos_}\\t\\t{tok.ent_type_}\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>hørt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>reaktion svensker</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>hey champ smide link ser hearthstone henne</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>melder vold voldtægt viser sandt beviser diver...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>betaler omkring mb kb får nok tættere kb kb be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet label\n",
       "id                                                           \n",
       "2378                                               hørt     0\n",
       "1879                                  reaktion svensker     0\n",
       "42           hey champ smide link ser hearthstone henne     0\n",
       "457   melder vold voldtægt viser sandt beviser diver...     1\n",
       "3108  betaler omkring mb kb får nok tættere kb kb be...     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data splits \n",
    "_, _, y_train_orig, _ = load_dkhate(test_size=0.2)\n",
    "with open(os.getcwd()+\"/data/X_orig_preproc.pkl\", \"rb\") as f:\n",
    "    content = pickle.load(f)\n",
    "\n",
    "X_train_orig = content[\"X_train\"]\n",
    "train_orig = pd.DataFrame([X_train_orig, y_train_orig]).T\n",
    "train_orig.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2631/2631 [06:07<00:00,  7.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# lemmatize the texts\n",
    "train_orig[\"lemmas\"] = train_orig[\"tweet\"].progress_apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1174    scanne lortet pc markere tage underskrift ny d...\n",
       "3301    kunne klarer fyr stort se venn vej samme spor ...\n",
       "1390    fuck meget sol varme lille regn please dansk å...\n",
       "799     hvorfor fucking stor helvede fejre kristn hell...\n",
       "900     ingen udlænding ved grænse heller kriminell ku...\n",
       "Name: lemmas, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into toxic, non-toxic and all\n",
    "toxic_text = train_orig[train_orig[\"label\"] == 1][\"lemmas\"]\n",
    "nontoxic_text = train_orig[train_orig[\"label\"] == 0][\"lemmas\"]\n",
    "all_text =  train_orig[\"lemmas\"]\n",
    "\n",
    "NUM_TOXIC = len(toxic_text)\n",
    "NUM_NONTOXIC = len(nontoxic_text)\n",
    "NUM_TOTAL = len(all_text)\n",
    "\n",
    "toxic_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.getcwd()+\"/data/orig_dataset_splits.pkl\", \"rb\") as f:\n",
    "#     orig_oversampled = pickle.load(f)\n",
    "# X_oversampl = orig_oversampled[\"X training preprocessed and oversampled\"]\n",
    "# y_oversampl = orig_oversampled[\"y training preprocessed and oversampled\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_oversampl = pd.DataFrame([X_oversampl, y_oversampl]).T\n",
    "# train_oversampl.rename(columns={\"Unnamed 0\": \"tweet\"}, inplace=True)\n",
    "# train_oversampl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lemmatize the texts\n",
    "# train_oversampl[\"lemmas\"] = train_oversampl[\"tweet\"].progress_apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split into toxic, non-toxic and all\n",
    "# toxic_text_oversampl = train_oversampl[train_oversampl[\"label\"] == 1][\"lemmas\"]\n",
    "# nontoxic_text_oversampl = train_oversampl[train_oversampl[\"label\"] == 0][\"lemmas\"]\n",
    "# all_text_oversampl = train_oversampl[\"lemmas\"]\n",
    "\n",
    "# NUM_TOXIC_OVERSAMPL = len(toxic_text_oversampl)\n",
    "# NUM_NONTOXIC_OVERSAMPL = len(nontoxic_text_oversampl)\n",
    "# NUM_TOTAL_OVERSAMPL = len(all_text_oversampl)\n",
    "\n",
    "# toxic_text_oversampl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load identity terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 unique identity lemmas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity_term</th>\n",
       "      <th>identity_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>transpersonerne</td>\n",
       "      <td>transperson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>transvestitterne</td>\n",
       "      <td>transvestit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>transerne</td>\n",
       "      <td>trans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>androgynerne</td>\n",
       "      <td>androgyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>hermafroditterne</td>\n",
       "      <td>hermafrodit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        identity_term identity_lemma\n",
       "155   transpersonerne    transperson\n",
       "156  transvestitterne    transvestit\n",
       "157         transerne          trans\n",
       "158      androgynerne       androgyn\n",
       "159  hermafroditterne    hermafrodit"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load identity terms\n",
    "identities = pd.read_excel(os.getcwd()+\"/data/identity_terms.xlsx\")\n",
    "print(len(set(identities[\"identity_lemma\"])), \"unique identity lemmas\")\n",
    "identities.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:09<00:00, 16.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 unique lemmatized identity terms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity_term</th>\n",
       "      <th>identity_lemma</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>transpersonerne</td>\n",
       "      <td>transperson</td>\n",
       "      <td>transperson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>transvestitterne</td>\n",
       "      <td>transvestit</td>\n",
       "      <td>transvestitterne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>transerne</td>\n",
       "      <td>trans</td>\n",
       "      <td>transe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>androgynerne</td>\n",
       "      <td>androgyn</td>\n",
       "      <td>androgynerne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>hermafroditterne</td>\n",
       "      <td>hermafrodit</td>\n",
       "      <td>hermafroditterne</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        identity_term identity_lemma        lemmatized\n",
       "155   transpersonerne    transperson       transperson\n",
       "156  transvestitterne    transvestit  transvestitterne\n",
       "157         transerne          trans            transe\n",
       "158      androgynerne       androgyn      androgynerne\n",
       "159  hermafroditterne    hermafrodit  hermafroditterne"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatize the identity terms\n",
    "identities[\"lemmatized\"] = identities[\"identity_term\"].progress_apply(lemmatize_text)\n",
    "print(len(set(identities[\"lemmatized\"])), \"unique lemmatized identity terms\")\n",
    "identities.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map from lemmatized word to the actual lemma\n",
    "lemmatized_2_lemma = dict(zip(identities[\"lemmatized\"], identities[\"identity_lemma\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully scraped the webpage with the title: \"Sankt Mortens Kirke (Næstved)\"\n",
      "____________________________________________________________________________________________________\n",
      "55°13′47″N 11°45′39″Ø﻿ / ﻿55.2297°N 11.7608°Ø﻿ / 55.2297; 11.7608Koordinater: 55°13′47″N 11°45′39″Ø﻿ / ﻿55.2297°N 11.7608°Ø﻿ / 55.2297; 11.7608\n",
      "Sankt Mortens Kirke er beliggende i Næstved centrum og er en af byens gamle middelalderkirker. Den er kendt fra en tidlig optegnelse omkring 1280, men menes at være bygget og taget i brug omkring 1200.\n",
      "\n",
      "Kirken, der fra middelalderen blev bygget til at være byens sognekirke, mens de andre kirke var tættere knyttet til ordensvæsenet, er opkaldt efter den legendariske Sankt Martin af Tours, på dansk kaldt Sankt Morten.\n",
      "Sankt Morten fejrer man i Danmark på Skt. Mortens aften den 10. november (Skt. Mortens Dag er den 11. november). Ifølge legenden ville Martin af Tours ikke udnævnes til biskop og gemte sig i en gåsesti. Gæssene afslørede ham ved deres høje skræppen, hvorefter han blev fundet af sine ivrige tilhængere, der sidenhen kårede ham til biskop. Som tak for sidst skal der gås på bordet hver Sankt Mortens aften til minde om Morten, der gemte sig i gåsestien.\n",
      "I kirkens hvælvinger kan man se et klart portræt af Sankt Martin af Tours (Sankt Morten), der bygger på en anden kendt historie om denne helgen. På kalkmaleriet ser man ham som soldat siddende på sin hest, mens han skærer et stykke af sin officerskappe for at give den til en fattig tigger. Derfor regnes Sankt Morten for skytshelgen for fattige og tiggere.\n",
      "\n",
      "Kirkens Frobenius-orgel har 41 stemmer og blev bygget i 1975.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "content = scrape_wiki_text(\"https://da.wikipedia.org/wiki/Sankt_Mortens_Kirke_(N%C3%A6stved)\")\n",
    "print(\"_\"*100)\n",
    "for text in content:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Data Supplemenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of identity terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should return False. Result: False\n",
      "This should return True.  Result: True\n"
     ]
    }
   ],
   "source": [
    "# test function\n",
    "print(\"This should return False. Result:\", occurs_in_string(\"mor\", \"elsker din humor\"))\n",
    "print(\"This should return True.  Result:\", occurs_in_string(\"mor\", \"hans mor er pænt sød\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many texts these terms occur in\n",
    "lemmatized_identities = list(set(identities[\"lemmatized\"]))\n",
    "occur_in_n_texts = {\"lemmatized_identity\": lemmatized_identities, \"toxic_count\": [], \"nontoxic_count\":[], \"total_count\":[]}\n",
    "\n",
    "for lemma in lemmatized_identities:\n",
    "    occur_in_n_texts[\"toxic_count\"].append(toxic_text.apply(lambda x: int(occurs_in_string(target=lemma, text=x))).sum())\n",
    "    occur_in_n_texts[\"nontoxic_count\"].append(nontoxic_text.apply(lambda x: int(occurs_in_string(target=lemma, text=x))).sum())\n",
    "    occur_in_n_texts[\"total_count\"].append(all_text.apply(lambda x: (occurs_in_string(target=lemma, text=x))).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>toxic_count</th>\n",
       "      <th>nontoxic_count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>toxic_pct</th>\n",
       "      <th>nontoxic_pct</th>\n",
       "      <th>total_pct</th>\n",
       "      <th>tox_total_diff</th>\n",
       "      <th>tox_total_abs_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mand</td>\n",
       "      <td>16</td>\n",
       "      <td>57</td>\n",
       "      <td>73</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kvinde</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>33</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fyr</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mandfolk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kvindfolk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tøs</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>søn</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fætter</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kone</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mor</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>far</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>dreng</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>kusine</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>søster</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>herre</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>pige</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>bror</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>datter</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>dame</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lemma  toxic_count  nontoxic_count  total_count  toxic_pct  \\\n",
       "0        mand           16              57           73       4.60   \n",
       "1      kvinde            7              26           33       2.01   \n",
       "2         fyr            1               0            1       0.29   \n",
       "3    mandfolk            1               0            1       0.29   \n",
       "4       queer            1               0            1       0.29   \n",
       "5   kvindfolk            1               0            1       0.29   \n",
       "6         tøs            1               0            1       0.29   \n",
       "7         søn            1               1            2       0.29   \n",
       "8      fætter            1               2            3       0.29   \n",
       "9        kone            2               9           11       0.57   \n",
       "10        mor            1               5            6       0.29   \n",
       "11        far            1               5            6       0.29   \n",
       "37      dreng            1               7            8       0.29   \n",
       "38     kusine            0               1            1       0.00   \n",
       "39     søster            0               2            2       0.00   \n",
       "40      herre            0               3            3       0.00   \n",
       "41       pige            1              10           11       0.29   \n",
       "42       bror            1              11           12       0.29   \n",
       "43     datter            0               5            5       0.00   \n",
       "44       dame            0               5            5       0.00   \n",
       "\n",
       "    nontoxic_pct  total_pct  tox_total_diff  tox_total_abs_diff  \n",
       "0           2.50       2.77            1.82                1.82  \n",
       "1           1.14       1.25            0.76                0.76  \n",
       "2           0.00       0.04            0.25                0.25  \n",
       "3           0.00       0.04            0.25                0.25  \n",
       "4           0.00       0.04            0.25                0.25  \n",
       "5           0.00       0.04            0.25                0.25  \n",
       "6           0.00       0.04            0.25                0.25  \n",
       "7           0.04       0.08            0.21                0.21  \n",
       "8           0.09       0.11            0.17                0.17  \n",
       "9           0.39       0.42            0.16                0.16  \n",
       "10          0.22       0.23            0.06                0.06  \n",
       "11          0.22       0.23            0.06                0.06  \n",
       "37          0.31       0.30           -0.02                0.02  \n",
       "38          0.04       0.04           -0.04                0.04  \n",
       "39          0.09       0.08           -0.08                0.08  \n",
       "40          0.13       0.11           -0.11                0.11  \n",
       "41          0.44       0.42           -0.13                0.13  \n",
       "42          0.48       0.46           -0.17                0.17  \n",
       "43          0.22       0.19           -0.19                0.19  \n",
       "44          0.22       0.19           -0.19                0.19  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create df with these occurrence numbers\n",
    "occurrence_df = pd.DataFrame(occur_in_n_texts)\n",
    "\n",
    "# map back to actual lemma and aggregate duplicates\n",
    "occurrence_df[\"lemma\"] = occurrence_df[\"lemmatized_identity\"].map(lemmatized_2_lemma)\n",
    "occurrence_df = occurrence_df.groupby(\"lemma\").agg({\"toxic_count\": \"sum\", \"nontoxic_count\": \"sum\", \"total_count\": \"sum\"}).reset_index()\n",
    "\n",
    "# calculate percentages\n",
    "occurrence_df[\"toxic_pct\"] = (occurrence_df[\"toxic_count\"]/NUM_TOXIC)*100 \n",
    "occurrence_df[\"nontoxic_pct\"] = (occurrence_df[\"nontoxic_count\"]/NUM_NONTOXIC)*100 \n",
    "occurrence_df[\"total_pct\"] = (occurrence_df[\"total_count\"]/NUM_TOTAL)*100 \n",
    "\n",
    "# calculate differences\n",
    "occurrence_df[\"tox_total_diff\"] = occurrence_df[\"toxic_pct\"] - occurrence_df[\"total_pct\"]\n",
    "occurrence_df[\"tox_total_abs_diff\"] = abs(occurrence_df[\"toxic_pct\"] - occurrence_df[\"total_pct\"])\n",
    "\n",
    "# sort by difference\n",
    "sorted_occurrence_df = occurrence_df.sort_values(\"tox_total_diff\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# display rows where toxic pct != total pct\n",
    "sorted_occurrence_df[sorted_occurrence_df[\"tox_total_diff\"] != 0].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this df\n",
    "sorted_occurrence_df.to_excel(os.getcwd()+\"/mitigation/frequency_of_identity_lemmas.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ones with a difference > 0 are the ones that I need to look at. \n",
    "\n",
    "I can actually make a difference here by adding non-toxic data and getting the toxic_pct number closer to the total_pct number, thereby reducing the difference so it's as close to zero as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # count how many texts these terms occur in\n",
    "# occur_in_n_texts_oversampl = {\"lemmatized_identity\": lemmatized_identities, \"toxic_count\": [], \"nontoxic_count\":[], \"total_count\":[]}\n",
    "\n",
    "# for lemma in lemmatized_identities:\n",
    "#     occur_in_n_texts_oversampl[\"toxic_count\"].append(toxic_text_oversampl.apply(lambda x: int(occurs_in_string(target=lemma, text=x))).sum())\n",
    "#     occur_in_n_texts_oversampl[\"nontoxic_count\"].append(nontoxic_text_oversampl.apply(lambda x: int(occurs_in_string(target=lemma, text=x))).sum())\n",
    "#     occur_in_n_texts_oversampl[\"total_count\"].append(all_text_oversampl.apply(lambda x: int(occurs_in_string(target=lemma, text=x))).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create df with these occurrence numbers\n",
    "# occurrence_df_oversampl = pd.DataFrame(occur_in_n_texts_oversampl)\n",
    "\n",
    "# # map back to actual lemma and aggregate duplicates\n",
    "# occurrence_df_oversampl[\"lemma\"] = occurrence_df_oversampl[\"lemmatized_identity\"].map(lemmatized_2_lemma)\n",
    "# occurrence_df_oversampl = occurrence_df_oversampl.groupby(\"lemma\").agg({\"toxic_count\": \"sum\", \"nontoxic_count\": \"sum\", \"total_count\": \"sum\"}).reset_index()\n",
    "\n",
    "# # calculate percentages\n",
    "# occurrence_df_oversampl[\"toxic_pct\"] = (occurrence_df_oversampl[\"toxic_count\"]/NUM_TOXIC_OVERSAMPL)*100 \n",
    "# occurrence_df_oversampl[\"nontoxic_pct\"] = (occurrence_df_oversampl[\"nontoxic_count\"]/NUM_NONTOXIC_OVERSAMPL)*100 \n",
    "# occurrence_df_oversampl[\"total_pct\"] = (occurrence_df_oversampl[\"total_count\"]/NUM_TOTAL_OVERSAMPL)*100 \n",
    "\n",
    "# # calculate differences\n",
    "# occurrence_df_oversampl[\"tox_total_diff\"] = occurrence_df_oversampl[\"toxic_pct\"] - occurrence_df_oversampl[\"total_pct\"]\n",
    "# occurrence_df_oversampl[\"tox_total_abs_diff\"] = abs(occurrence_df_oversampl[\"toxic_pct\"] - occurrence_df_oversampl[\"total_pct\"])\n",
    "\n",
    "# # sort by difference\n",
    "# sorted_occurrence_df_oversampl = occurrence_df_oversampl.sort_values(\"tox_total_diff\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# # display rows where toxic pct != total pct\n",
    "# sorted_occurrence_df_oversampl[sorted_occurrence_df_oversampl[\"tox_total_diff\"] != 0].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save this df\n",
    "# sorted_occurrence_df_oversampl.to_excel(os.getcwd()+\"/mitigation/frequency_of_identity_lemmas_oversampl.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is that *dreng* is now in the top part (positive). Some differences are smaller, some are larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length differences\n",
    "\n",
    "Percent of comments labeled as toxic at each length containing the given terms, e.g.:\n",
    "\n",
    "| Term | 20-59 | 60-179 |\n",
    "|:---:|:---:|:---:|\n",
    "| ALL | 17% | 12% |\n",
    "| gay | 88% | 77% |\n",
    "| queer | 75% | 83% |\n",
    "| ... | ... | ... |\n",
    "\n",
    "Other lengths:\n",
    "* 180-539\n",
    "* 540-1619\n",
    "* 1620-4859\n",
    "\n",
    "\n",
    "Method:\n",
    "\n",
    "* For each lemma:\n",
    "  * Find the texts that it occur in\n",
    "  * Separate these texts into 5 length buckets\n",
    "  * For each length_bucket:\n",
    "    * Find the percentage that are toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2631/2631 [00:00<00:00, 393552.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# add lengths to df\n",
    "train_orig[\"length\"] = train_orig[\"tweet\"].progress_apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min length: 0\n",
      "Max length: 3518\n"
     ]
    }
   ],
   "source": [
    "# divide into 6 buckets\n",
    "print(\"Min length:\", train_orig[\"length\"].min())\n",
    "print(\"Max length:\", train_orig[\"length\"].max())\n",
    "\n",
    "bin1 = train_orig.query(\"0 <= length <= 19\") # 20\n",
    "bin2 = train_orig.query(\"20 <= length <= 59\") # 40\n",
    "bin3 = train_orig.query(\"60 <= length <= 139\") # 80\n",
    "bin4 = train_orig.query(\"140 <= length <= 299\") # 160\n",
    "bin5 = train_orig.query(\"300 <= length <= 619\") # 320\n",
    "bin6 = train_orig.query(\"620 <= length\") # the rest\n",
    "bins = [bin1, bin2, bin3, bin4, bin5, bin6]\n",
    "bin_labels = [\"0-19\", \"20-59\", \"60-139\", \"140-299\", \"300-619\", \"620-3519\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>bin_range</th>\n",
       "      <th>0-19</th>\n",
       "      <th>20-59</th>\n",
       "      <th>60-139</th>\n",
       "      <th>140-299</th>\n",
       "      <th>300-619</th>\n",
       "      <th>620-3519</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALL</th>\n",
       "      <td>10.74</td>\n",
       "      <td>12.79</td>\n",
       "      <td>13.75</td>\n",
       "      <td>17.5</td>\n",
       "      <td>29.63</td>\n",
       "      <td>33.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "bin_range   0-19  20-59  60-139  140-299  300-619  620-3519\n",
       "ALL        10.74  12.79   13.75     17.5    29.63     33.33"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find proportion of toxic comments for each bin (no specific terms)\n",
    "results = {\"bin_range\":bin_labels, \"toxic\":[], \"nontoxic\":[]}\n",
    "for bin in bins: # length bins\n",
    "    results[\"toxic\"].append(len(bin[bin[\"label\"] == 1])) # count toxic in that bin\n",
    "    results[\"nontoxic\"].append(len(bin[bin[\"label\"] == 0])) # and non-toxic\n",
    "\n",
    "# prepare preliminary results df\n",
    "prel_results_df = pd.DataFrame(results)\n",
    "prel_results_df[\"pct_toxic\"] = ( prel_results_df[\"toxic\"] / (prel_results_df[\"toxic\"]+prel_results_df[\"nontoxic\"]) ) * 100 # add percentage\n",
    "prel_results_df.set_index(\"bin_range\", inplace=True)\n",
    "\n",
    "# add to final results df\n",
    "results_df_1 = prel_results_df[[\"pct_toxic\"]].T\n",
    "results_df_1.index = [\"ALL\"]\n",
    "results_df_1.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for each lemma\n",
    "\n",
    "# prepare dicts\n",
    "toxic_count_dict = {\"lemmatized_identity\": lemmatized_identities}\n",
    "total_count_dict = {\"lemmatized_identity\": lemmatized_identities}\n",
    "for label in bin_labels:\n",
    "    toxic_count_dict[label] = []\n",
    "    total_count_dict[label] = []\n",
    "    \n",
    "for lemma in lemmatized_identities: # for each lemma\n",
    "    for (bin_label, bin) in zip(bin_labels, bins): # for each bin\n",
    "        \n",
    "        # count no. of toxic/all texts this lemma occurs in in this bin\n",
    "        toxic_count = bin[bin[\"label\"]==1][\"lemmas\"].apply(lambda x: int(occurs_in_string(target=lemma, text=x))).sum() \n",
    "        total_count = bin[\"lemmas\"].apply(lambda x: int(occurs_in_string(target=lemma, text=x))).sum() \n",
    "        \n",
    "        # add to count_dicts\n",
    "        toxic_count_dict[bin_label].append(toxic_count)\n",
    "        total_count_dict[bin_label].append(total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df with these occurrence numbers\n",
    "toxic_count_df = pd.DataFrame(toxic_count_dict)\n",
    "total_count_df = pd.DataFrame(total_count_dict)\n",
    "\n",
    "# map back to actual lemma and aggregate duplicates\n",
    "toxic_count_df[\"lemma\"] = toxic_count_df[\"lemmatized_identity\"].map(lemmatized_2_lemma)\n",
    "toxic_count_df = toxic_count_df.groupby(\"lemma\").agg({\"0-19\": \"sum\", \"20-59\": \"sum\", \"60-139\": \"sum\", \"140-299\": \"sum\", \"300-619\": \"sum\", \"620-3519\": \"sum\"}).reset_index()\n",
    "toxic_count_df[\"sum\"] = toxic_count_df[\"0-19\"] + toxic_count_df[\"20-59\"] + toxic_count_df[\"60-139\"] + toxic_count_df[\"140-299\"] + toxic_count_df[\"300-619\"] + toxic_count_df[\"620-3519\"]\n",
    "toxic_count_df = toxic_count_df.sort_values(\"lemma\")\n",
    "total_count_df[\"lemma\"] = total_count_df[\"lemmatized_identity\"].map(lemmatized_2_lemma)\n",
    "total_count_df = total_count_df.groupby(\"lemma\").agg({\"0-19\": \"sum\", \"20-59\": \"sum\", \"60-139\": \"sum\", \"140-299\": \"sum\", \"300-619\": \"sum\", \"620-3519\": \"sum\"}).reset_index()\n",
    "total_count_df[\"sum\"] = total_count_df[\"0-19\"] + total_count_df[\"20-59\"] + total_count_df[\"60-139\"] + total_count_df[\"140-299\"] + total_count_df[\"300-619\"] + total_count_df[\"620-3519\"]\n",
    "total_count_df = total_count_df.sort_values(\"lemma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0-19', '20-59', '60-139', '140-299', '300-619', '620-3519'], dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_count_df.columns[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to results df\n",
    "results_df_2 = toxic_count_df[[\"lemma\"]]\n",
    "for col in toxic_count_df.columns[1:-1]:\n",
    "    results_df_2[col] = (toxic_count_df[col] / total_count_df[col]) * 100 # calculate percentages\n",
    "results_df_2.set_index(\"lemma\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0-19</th>\n",
       "      <th>20-59</th>\n",
       "      <th>60-139</th>\n",
       "      <th>140-299</th>\n",
       "      <th>300-619</th>\n",
       "      <th>620-3519</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALL</th>\n",
       "      <td>10.74</td>\n",
       "      <td>12.79</td>\n",
       "      <td>13.75</td>\n",
       "      <td>17.5</td>\n",
       "      <td>29.63</td>\n",
       "      <td>33.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bror</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dame</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datter</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dreng</th>\n",
       "      <td></td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fyr</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>100.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fætter</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>herre</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kone</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kusine</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kvinde</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>16.67</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kvindfolk</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>100.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mand</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mandfolk</th>\n",
       "      <td></td>\n",
       "      <td>100.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mor</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>33.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pige</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queer</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>søn</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>søster</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tøs</th>\n",
       "      <td>100.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0-19  20-59 60-139 140-299 300-619 620-3519\n",
       "ALL        10.74  12.79  13.75    17.5   29.63    33.33\n",
       "bror                0.0    0.0     0.0     0.0     50.0\n",
       "dame                       0.0     0.0                 \n",
       "datter                     0.0     0.0     0.0      0.0\n",
       "dreng             100.0    0.0                      0.0\n",
       "far                 0.0    0.0    50.0              0.0\n",
       "fyr                      100.0                         \n",
       "fætter              0.0          100.0     0.0         \n",
       "herre               0.0    0.0                         \n",
       "kone                0.0    0.0     0.0   100.0     50.0\n",
       "kusine              0.0                                \n",
       "kvinde       0.0   12.5  16.67    40.0     0.0     20.0\n",
       "kvindfolk                                100.0         \n",
       "mand         0.0    8.7   50.0    25.0    25.0    16.67\n",
       "mandfolk          100.0                                \n",
       "mor                      33.33     0.0     0.0      0.0\n",
       "pige                0.0  33.33     0.0     0.0      0.0\n",
       "queer                                             100.0\n",
       "søn                        0.0   100.0                 \n",
       "søster                     0.0     0.0                 \n",
       "tøs        100.0                                       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final df\n",
    "results_df = pd.concat([results_df_1, results_df_2])\n",
    "results_df.dropna(axis = 0, how = 'all', inplace = True) # drop rows with all NA values\n",
    "display(results_df.round(2).fillna(\"\")) # show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "results_df = results_df.fillna(\"\") # fill NAs\n",
    "results_df.to_excel(os.getcwd()+\"/mitigation/toxicity_at_diff_lengths.xlsx\") # save as xlsx file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate how much new data is needed\n",
    "Based on:\n",
    "https://github.com/conversationai/unintended-ml-bias-analysis/blob/main/archive/unintended_ml_bias/Dataset_bias_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pseudocode\n",
    "# num_nontoxic_to_add = {}\n",
    "\n",
    "# for word in list_of_words_to_fix:\n",
    "#   for length:\n",
    "#       t = get t from toxic_count_df\n",
    "#       n = get n from total_count_df - t\n",
    "#       f = get from results_df.loc[ALL, bin_label]\n",
    "#       a = calculate_nontoxic_to_add(f=f, n=n, t=t, method=\"round\")\n",
    "#       num_nontoxic_to_add[word] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nontoxic_to_add(f:float, n:int, t:int, method:str) -> int:\n",
    "    \"\"\"Calculate how many non-toxic examples you need to add to get the desired non-toxic fraction.\n",
    "\n",
    "    Args:\n",
    "        f (float): desired non-toxic fraction.\n",
    "        n (int): current number of non-toxic examples.\n",
    "        t (int): current number of toxic examples.\n",
    "        method (str): method to convert result to int: \"round\", \"ceiling\", or \"floor\".\n",
    "\n",
    "    Returns:\n",
    "        int: number of non-toxic examples to add.    \n",
    "    \"\"\"\n",
    "    a = (f*(t+n)-n) / (1-f)\n",
    "    \n",
    "    method = method.lower()\n",
    "    if method == \"round\":\n",
    "        return round(a)\n",
    "    elif method == \"ceiling\":\n",
    "        return int(np.ceil(a))\n",
    "    elif method == \"floor\":\n",
    "        return int(np.floor(a))\n",
    "    else:\n",
    "        raise Exception(\"Unknown method. Must be either 'round', 'ceiling', or 'floor'.\")\n",
    "\n",
    "def calculate_nontoxic_fraction(n:float, t:float, a:int) -> float:\n",
    "    \"\"\"Returns the fraction of non-toxic examples.\n",
    "\n",
    "    Args:\n",
    "        n (int): current number of non-toxic examples.\n",
    "        t (int): current number of toxic examples.\n",
    "        a (int): number of non-toxic examples to add.\n",
    "\n",
    "    Returns:\n",
    "        float: non-toxic fraction.\n",
    "    \"\"\"\n",
    "    f = (n+a) / (t+n+a)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # example (mand 140-?)\n",
    "# t = 6 # current number of toxic examples\n",
    "# n = 18 # current number of non-toxic examples\n",
    "# a = calculate_nontoxic_to_add(f=0.825, n=n, t=t, method=\"round\")\n",
    "# f = calculate_nontoxic_fraction(n=n, t=t, a=a) # new toxic fraction\n",
    "\n",
    "# print(\"Old non-toxic fraction  :\", round(calculate_nontoxic_fraction(n=n, t=t, a=0), 4))\n",
    "# print(\"Add n non-toxic examples:\", a)\n",
    "# print(\"New non-toxic fraction  :\", round(calculate_nontoxic_fraction(n=n, t=t, a=a), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # example (pige 60-?)\n",
    "# t = 1 # current number of toxic examples\n",
    "# n = 2 # current number of non-toxic examples\n",
    "# a = calculate_nontoxic_to_add(f=0.8625, n=n, t=t, method=\"round\")\n",
    "# f = calculate_nontoxic_fraction(n=n, t=t, a=a) # new toxic fraction\n",
    "\n",
    "# print(\"Old toxic fraction      :\", round(calculate_nontoxic_fraction(n=n, t=t, a=0), 4))\n",
    "# print(\"Add n non-toxic examples:\", a)\n",
    "# print(\"New toxic fraction      :\", round(calculate_nontoxic_fraction(n=n, t=t, a=a), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEMMA\t\tLENGTH\t\tTOXIC%\n",
      "bror     \t620-3519\t 50.00 %\n",
      "dreng    \t20-59   \t100.00 %\n",
      "far      \t140-299 \t 50.00 %\n",
      "fyr      \t60-139  \t100.00 %\n",
      "fætter   \t140-299 \t100.00 %\n",
      "kone     \t300-619 \t100.00 %\n",
      "kone     \t620-3519\t 50.00 %\n",
      "kvinde   \t60-139  \t 16.67 %\n",
      "kvinde   \t140-299 \t 40.00 %\n",
      "kvindfolk\t300-619 \t100.00 %\n",
      "mand     \t60-139  \t 50.00 %\n",
      "mand     \t140-299 \t 25.00 %\n",
      "mandfolk \t20-59   \t100.00 %\n",
      "mor      \t60-139  \t 33.33 %\n",
      "pige     \t60-139  \t 33.33 %\n",
      "queer    \t620-3519\t100.00 %\n",
      "søn      \t140-299 \t100.00 %\n",
      "tøs      \t0-19    \t100.00 %\n"
     ]
    }
   ],
   "source": [
    "# find words to fix\n",
    "overall_prior_distributions = results_df.iloc[0, :] \n",
    "lengths = overall_prior_distributions.keys()\n",
    "unbalanced_lemmas_at_lengths = {}\n",
    "\n",
    "print(\"LEMMA\\t\\tLENGTH\\t\\tTOXIC%\")\n",
    "for row in results_df.iloc[1:,:].iterrows(): # for each unbalanced row\n",
    "    lemma = row[0]\n",
    "    content = row[1]\n",
    "    \n",
    "    unbalanced_lengths = []\n",
    "    for i, x in enumerate(content): # for each column (= length bucket)\n",
    "        if type(x) == float and x >= overall_prior_distributions.iloc[i]: # if the percentage of toxic is larger than the prior distribution \n",
    "            print(f\"{lemma.ljust(9)}\\t{lengths[i].ljust(8)}\\t{x:6.2f} %\") \n",
    "            unbalanced_lengths.append(lengths[i])        \n",
    "    if unbalanced_lengths: # if not empty\n",
    "        unbalanced_lemmas_at_lengths[lemma] = unbalanced_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bror': ['620-3519'],\n",
       " 'dreng': ['20-59'],\n",
       " 'far': ['140-299'],\n",
       " 'fyr': ['60-139'],\n",
       " 'fætter': ['140-299'],\n",
       " 'kone': ['300-619', '620-3519'],\n",
       " 'kvinde': ['60-139', '140-299'],\n",
       " 'kvindfolk': ['300-619'],\n",
       " 'mand': ['60-139', '140-299'],\n",
       " 'mandfolk': ['20-59'],\n",
       " 'mor': ['60-139'],\n",
       " 'pige': ['60-139'],\n",
       " 'queer': ['620-3519'],\n",
       " 'søn': ['140-299'],\n",
       " 'tøs': ['0-19']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display words to fix\n",
    "unbalanced_lemmas_at_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Total to add: 114\n"
     ]
    }
   ],
   "source": [
    "# find a for each unbalanced lemma at length\n",
    "\n",
    "num_nontoxic_to_add = {}\n",
    "old_new_nontoxic_frac = {}\n",
    "total_to_add = 0\n",
    "\n",
    "for lemma in unbalanced_lemmas_at_lengths: # for word in list_of_words_to_fix:\n",
    "    \n",
    "    for length in unbalanced_lemmas_at_lengths[lemma]: # for length\n",
    "    \n",
    "        current_toxic = toxic_count_df[toxic_count_df[\"lemma\"]==lemma][length].iloc[0] #  t = get t from toxic_count_df\n",
    "        current_total = total_count_df[total_count_df[\"lemma\"]==lemma][length].iloc[0]\n",
    "        current_nontoxic = current_total - current_toxic # n = get n from total_count_df - t\n",
    "        desired_f = 1 - (overall_prior_distributions[length]/100) # f = 1 - toxic frac (get this from overall_prior_distributions/100 (results_df.loc[ALL, bin_label]))\n",
    "        add_n_nontoxic = calculate_nontoxic_to_add(f=desired_f, n=current_nontoxic, t=current_toxic, method=\"round\")\n",
    "        \n",
    "        num_nontoxic_to_add[(lemma, length)] = add_n_nontoxic\n",
    "        new_f = calculate_nontoxic_fraction(n=current_nontoxic, t=current_toxic, a=add_n_nontoxic)\n",
    "        old_new_nontoxic_frac[(lemma, length)] = (desired_f, new_f)\n",
    "        total_to_add += add_n_nontoxic\n",
    "print(\"Done\")\n",
    "print(\"Total to add:\", total_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lemma, length): number to add\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('bror', '620-3519'): 1,\n",
       " ('dreng', '20-59'): 7,\n",
       " ('far', '140-299'): 4,\n",
       " ('fyr', '60-139'): 6,\n",
       " ('fætter', '140-299'): 5,\n",
       " ('kone', '300-619'): 2,\n",
       " ('kone', '620-3519'): 1,\n",
       " ('kvinde', '60-139'): 1,\n",
       " ('kvinde', '140-299'): 13,\n",
       " ('kvindfolk', '300-619'): 2,\n",
       " ('mand', '60-139'): 32,\n",
       " ('mand', '140-299'): 10,\n",
       " ('mandfolk', '20-59'): 7,\n",
       " ('mor', '60-139'): 4,\n",
       " ('pige', '60-139'): 4,\n",
       " ('queer', '620-3519'): 2,\n",
       " ('søn', '140-299'): 5,\n",
       " ('tøs', '0-19'): 8}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display results\n",
    "print(\"(lemma, length): number to add\")\n",
    "num_nontoxic_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>old_f</th>\n",
       "      <th>new_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bror</th>\n",
       "      <th>620-3519</th>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dreng</th>\n",
       "      <th>20-59</th>\n",
       "      <td>0.8721</td>\n",
       "      <td>0.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far</th>\n",
       "      <th>140-299</th>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fyr</th>\n",
       "      <th>60-139</th>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.8571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fætter</th>\n",
       "      <th>140-299</th>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">kone</th>\n",
       "      <th>300-619</th>\n",
       "      <td>0.7037</td>\n",
       "      <td>0.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620-3519</th>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">kvinde</th>\n",
       "      <th>60-139</th>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.8571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140-299</th>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.8261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kvindfolk</th>\n",
       "      <th>300-619</th>\n",
       "      <td>0.7037</td>\n",
       "      <td>0.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">mand</th>\n",
       "      <th>60-139</th>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.8636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140-299</th>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.8235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mandfolk</th>\n",
       "      <th>20-59</th>\n",
       "      <td>0.8721</td>\n",
       "      <td>0.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mor</th>\n",
       "      <th>60-139</th>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.8571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pige</th>\n",
       "      <th>60-139</th>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.8571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queer</th>\n",
       "      <th>620-3519</th>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>søn</th>\n",
       "      <th>140-299</th>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tøs</th>\n",
       "      <th>0-19</th>\n",
       "      <td>0.8926</td>\n",
       "      <td>0.8889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     old_f   new_f\n",
       "bror      620-3519  0.6667  0.6667\n",
       "dreng     20-59     0.8721  0.8750\n",
       "far       140-299   0.8250  0.8333\n",
       "fyr       60-139    0.8625  0.8571\n",
       "fætter    140-299   0.8250  0.8333\n",
       "kone      300-619   0.7037  0.6667\n",
       "          620-3519  0.6667  0.6667\n",
       "kvinde    60-139    0.8625  0.8571\n",
       "          140-299   0.8250  0.8261\n",
       "kvindfolk 300-619   0.7037  0.6667\n",
       "mand      60-139    0.8625  0.8636\n",
       "          140-299   0.8250  0.8235\n",
       "mandfolk  20-59     0.8721  0.8750\n",
       "mor       60-139    0.8625  0.8571\n",
       "pige      60-139    0.8625  0.8571\n",
       "queer     620-3519  0.6667  0.6667\n",
       "søn       140-299   0.8250  0.8333\n",
       "tøs       0-19      0.8926  0.8889"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display old and new nontoxic fraction\n",
    "old_new_nontoxic_frac_df = pd.DataFrame(old_new_nontoxic_frac).T\n",
    "old_new_nontoxic_frac_df.rename(columns={0:\"old_f\", 1:\"new_f\"}, inplace=True)\n",
    "old_new_nontoxic_frac_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now:\n",
    "# for each word to add:\n",
    "    # find page that mentions this word\n",
    "    # scrape this page\n",
    "    # add text to big text bank\n",
    "\n",
    "# for each word to add:\n",
    "    # search in text bank for passages that mentions this lemma\n",
    "    # extract these passages and divide them into sentences\n",
    "    # preprocess said passages\n",
    "    # if one matches the given length bucket, add it\n",
    "    # otherwise, go into sentences. if one of these match, then add it. otherwise, add this sentence + surrounding sentences until we get the desired length.\n",
    "\n",
    "# add to training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "search on wiki:\n",
    "\n",
    "- advanced search\n",
    "- one of these words: the four variants, e.g. \"bror, broren, brødre, brødrene\"\n",
    "- these categories: \"biografier\", \"filmskolefilm fra Danmark\", \"sange fra Danmark\"\n",
    "- sorted by relevance\n",
    "- top 1 result from each category\n",
    "- only difference is queer that had no results in these categories, so had to just search for \"queer\" and use three random pages (undgik hoved/definitionssiden)\n",
    "\n",
    "bror:\n",
    "- https://da.wikipedia.org/wiki/Hemming_Hartmann-Petersen\n",
    "- https://da.wikipedia.org/wiki/Zafir_(film_fra_2011)\n",
    "- https://da.wikipedia.org/wiki/Brdr._Gebis\n",
    "\n",
    "dreng\n",
    "- https://da.wikipedia.org/wiki/Mogens_Wenzel_Andreasen\n",
    "- https://da.wikipedia.org/wiki/Dreng_(dokumentarfilm)\n",
    "- https://da.wikipedia.org/wiki/We_Wanna_Be_Free \n",
    "\n",
    "far\n",
    "- https://da.wikipedia.org/wiki/Christian_Molbech # not top result, because it was a different word \"fædrene tro\" that was the hit\n",
    "- https://da.wikipedia.org/wiki/Vore_F%C3%A6dres_S%C3%B8nner\n",
    "- https://da.wikipedia.org/wiki/Ebbe_Skammels%C3%B8n # is this toxic? \"kvæste sin far\"\n",
    "\n",
    "fyr\n",
    "- XX MANGLER, SE KOMMENTAR NEDENFOR\n",
    "    - https://da.wikipedia.org/wiki/John_Green_(forfatter) (søgte på \"en ung fyr\")\n",
    "- https://da.wikipedia.org/wiki/LUCK.exe\n",
    "- https://da.wikipedia.org/wiki/Du_G%C3%B8r_Mig # not the first as the others were about \"FYR OG FLAMME\n",
    "\n",
    "fætter\n",
    "- https://da.wikipedia.org/wiki/Eleonore_Tscherning \n",
    "- INGEN MED FILM ELLER SANGE, DERFOR BARE TO FRA GENEREL SØGNING\n",
    "    - https://da.wikipedia.org/wiki/F%C3%A6tter_H%C3%B8jben\n",
    "    - https://da.wikipedia.org/wiki/Min_f%C3%A6tter_er_pirat\n",
    "\n",
    "kone\n",
    "- https://da.wikipedia.org/wiki/Ralf_Pittelkow\n",
    "- https://da.wikipedia.org/wiki/Deadline_(film_fra_2005) (ikke første, her var det en titel)\n",
    "- https://da.wikipedia.org/wiki/Krig_og_fred_(Shu-bi-dua)\n",
    "\n",
    "kvinde\n",
    "- https://da.wikipedia.org/wiki/Thora_Esche\n",
    "- https://da.wikipedia.org/wiki/Kvinden_(film)\n",
    "- https://da.wikipedia.org/wiki/Danske_sild_(Shu-bi-dua-sang)\n",
    "\n",
    "kvindfolk\n",
    "- ingen hits i de tre kategorier, derfor bare fra generel søgning\n",
    "    - https://da.wikipedia.org/wiki/G%C3%A5rd_fra_Pebringe,_Sj%C3%A6lland_(Frilandsmuseet)\n",
    "    - https://da.wikipedia.org/wiki/Sophie_Caroline_af_Ostfriesland\n",
    "    - https://da.wikipedia.org/wiki/Hospital\n",
    "\n",
    "mand\n",
    "- https://da.wikipedia.org/wiki/J.J._Dampe (ikke den første, fordi ordet kun optrådte i titler/værker der)\n",
    "- https://da.wikipedia.org/wiki/Manden_der_dr%C3%B8mte_at_han_v%C3%A5gnede\n",
    "- https://da.wikipedia.org/wiki/St%C3%A5r_p%C3%A5_en_alpetop\n",
    "\n",
    "mandfolk\n",
    "- ingen hits i de tre kategorier, derfor bare fra generel søgning (mange af disse var bare filmtitler, dvs. ikke sætninger)\n",
    "    - https://da.wikipedia.org/wiki/Louis_Marcussen\n",
    "    - https://da.wikipedia.org/wiki/Asterix_og_vikingerne_(tegnefilm)\n",
    "    - https://da.wikipedia.org/wiki/Lysets_rige\n",
    "\n",
    "mor\n",
    "- https://da.wikipedia.org/wiki/S%C3%B8sser_Krag\n",
    "- https://da.wikipedia.org/wiki/Kokon_(film_fra_2019)\n",
    "- https://da.wikipedia.org/wiki/Germand_Gladensvend (skippede dem vi havde allerede)\n",
    "\n",
    "pige\n",
    "- https://da.wikipedia.org/wiki/Jean-Paul_Sartre (samme som med sangen)\n",
    "- https://da.wikipedia.org/wiki/Forl%C3%B8sning\n",
    "- https://da.wikipedia.org/wiki/Den_danske_sang_er_en_ung,_blond_pige (første var kun titel)\n",
    "\n",
    "queer:\n",
    "- https://da.wikipedia.org/wiki/Warehouse9 (culture)\n",
    "- https://da.wikipedia.org/wiki/Babylebbe (movie)\n",
    "- https://da.wikipedia.org/wiki/Judith_Butler (person)\n",
    "\n",
    "søn\n",
    "- https://da.wikipedia.org/wiki/Christian_8.\n",
    "- https://da.wikipedia.org/wiki/F%C3%A6dreland_(film) (skippede dem vi havde allerede)\n",
    "- https://da.wikipedia.org/wiki/Titte_til_hinanden (skippede dem vi havde allerede)\n",
    "\n",
    "tøs\n",
    "- https://da.wikipedia.org/wiki/Stephanie_Le%C3%B3n (samme som ved sangen)\n",
    "- https://da.wikipedia.org/wiki/13_snart_30 (film tilladt for alle, da ingen hits ellers)\n",
    "- https://da.wikipedia.org/wiki/T%C3%A6t_p%C3%A5_-_live (generel søgning, for få hits ved specifik søgning)\n",
    "\n",
    "\n",
    "cannot find a biography that uses the word \"fyr\". mostly slang. can only find ones that use \"fyret\" (e.g. \"fyret fra sit arbejde\") or \"fyrre\"\n",
    "\n",
    "\n",
    "**Decided to add more for the words where len(passage) or len(sentence) was not enough (just from general search)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://da.wikipedia.org/wiki/Hemming_Hartmann-Petersen\",\n",
    "    \"https://da.wikipedia.org/wiki/Zafir_(film_fra_2011)\",\n",
    "    \"https://da.wikipedia.org/wiki/Brdr._Gebis\",\n",
    "    \"https://da.wikipedia.org/wiki/Mogens_Wenzel_Andreasen\",\n",
    "    \"https://da.wikipedia.org/wiki/Dreng_(dokumentarfilm)\",\n",
    "    \"https://da.wikipedia.org/wiki/We_Wanna_Be_Free\",\n",
    "    \"https://da.wikipedia.org/wiki/Christian_Molbech\",\n",
    "    \"https://da.wikipedia.org/wiki/Vore_F%C3%A6dres_S%C3%B8nner\",\n",
    "    \"https://da.wikipedia.org/wiki/Ebbe_Skammels%C3%B8n\",\n",
    "    \"https://da.wikipedia.org/wiki/John_Green_(forfatter)\",\n",
    "    \"https://da.wikipedia.org/wiki/LUCK.exe\",\n",
    "    \"https://da.wikipedia.org/wiki/Du_G%C3%B8r_Mig\",\n",
    "    \"https://da.wikipedia.org/wiki/Eleonore_Tscherning\",\n",
    "    \"https://da.wikipedia.org/wiki/F%C3%A6tter_H%C3%B8jben\",\n",
    "    \"https://da.wikipedia.org/wiki/Min_f%C3%A6tter_er_pirat\",\n",
    "    \"https://da.wikipedia.org/wiki/Ralf_Pittelkow\",\n",
    "    \"https://da.wikipedia.org/wiki/Deadline_(film_fra_2005)\",\n",
    "    \"https://da.wikipedia.org/wiki/Krig_og_fred_(Shu-bi-dua)\",\n",
    "    \"https://da.wikipedia.org/wiki/Thora_Esche\",\n",
    "    \"https://da.wikipedia.org/wiki/Kvinden_(film)\",\n",
    "    \"https://da.wikipedia.org/wiki/Danske_sild_(Shu-bi-dua-sang)\",\n",
    "    \"https://da.wikipedia.org/wiki/G%C3%A5rd_fra_Pebringe,_Sj%C3%A6lland_(Frilandsmuseet)\",\n",
    "    \"https://da.wikipedia.org/wiki/Sophie_Caroline_af_Ostfriesland\",\n",
    "    \"https://da.wikipedia.org/wiki/Hospital\",\n",
    "    \"https://da.wikipedia.org/wiki/J.J._Dampe\",\n",
    "    \"https://da.wikipedia.org/wiki/Manden_der_dr%C3%B8mte_at_han_v%C3%A5gnede\",\n",
    "    \"https://da.wikipedia.org/wiki/St%C3%A5r_p%C3%A5_en_alpetop\",\n",
    "    \"https://da.wikipedia.org/wiki/Louis_Marcussen\", # no hit\n",
    "    \"https://da.wikipedia.org/wiki/Asterix_og_vikingerne_(tegnefilm)\", # hit\n",
    "    \"https://da.wikipedia.org/wiki/Lysets_rige\", # no hit\n",
    "    \"https://da.wikipedia.org/wiki/S%C3%B8sser_Krag\",\n",
    "    \"https://da.wikipedia.org/wiki/Kokon_(film_fra_2019)\",\n",
    "    \"https://da.wikipedia.org/wiki/Germand_Gladensvend\",\n",
    "    \"https://da.wikipedia.org/wiki/Jean-Paul_Sartre\",\n",
    "    \"https://da.wikipedia.org/wiki/Forl%C3%B8sning\",\n",
    "    \"https://da.wikipedia.org/wiki/Den_danske_sang_er_en_ung,_blond_pige\",\n",
    "    \"https://da.wikipedia.org/wiki/Warehouse9\",\n",
    "    \"https://da.wikipedia.org/wiki/Babylebbe\",\n",
    "    \"https://da.wikipedia.org/wiki/Judith_Butler\",\n",
    "    \"https://da.wikipedia.org/wiki/Christian_8.\",\n",
    "    \"https://da.wikipedia.org/wiki/F%C3%A6dreland_(film)\",\n",
    "    \"https://da.wikipedia.org/wiki/Titte_til_hinanden\",\n",
    "    \"https://da.wikipedia.org/wiki/Stephanie_Le%C3%B3n\",\n",
    "    \"https://da.wikipedia.org/wiki/13_snart_30\",\n",
    "    \"https://da.wikipedia.org/wiki/T%C3%A6t_p%C3%A5_-_live\",\n",
    "    \n",
    "    # newly added (5 random from general search for lemmas that still need extra data)\n",
    "    \"https://da.wikipedia.org/wiki/Der_var_engang_en_dreng\",\n",
    "    \"https://da.wikipedia.org/wiki/Niels_Pind_og_hans_dreng\",\n",
    "    \"https://da.wikipedia.org/wiki/Smukke_dreng\",\n",
    "    \"https://da.wikipedia.org/wiki/Portr%C3%A6t_af_en_dreng\",\n",
    "    \"https://da.wikipedia.org/wiki/Drengen\",\n",
    "    \"https://da.wikipedia.org/wiki/Clint_Eastwood\",\n",
    "    \"https://da.wikipedia.org/wiki/Winfield_Scott\",\n",
    "    \"https://da.wikipedia.org/wiki/Sara_Bl%C3%A6del\",\n",
    "    \"https://da.wikipedia.org/wiki/David_Firth\",\n",
    "    \"https://da.wikipedia.org/wiki/Stephen_Dorff\",\n",
    "    \"https://da.wikipedia.org/wiki/F%C3%A6tter_Vims\",\n",
    "    \"https://da.wikipedia.org/wiki/F%C3%A6tter_Guf\",\n",
    "    \"https://da.wikipedia.org/wiki/F%C3%A6tter_BR\",\n",
    "    \"https://da.wikipedia.org/wiki/Agamemnon\",\n",
    "    \"https://da.wikipedia.org/wiki/Brylluppet_mellem_kronprinsesse_Victoria_og_Daniel_Westling\",\n",
    "    \"https://da.wikipedia.org/wiki/En_n%C3%B8gen_kvinde_s%C3%A6tter_sit_h%C3%A5r_foran_et_spejl\",\n",
    "    \"https://da.wikipedia.org/wiki/Kvinders_valgret\",\n",
    "    \"https://da.wikipedia.org/wiki/EM_i_fodbold_2022_(kvinder)\",\n",
    "    \"https://da.wikipedia.org/wiki/En_duft_af_kvinde\",\n",
    "    \"https://da.wikipedia.org/wiki/Kvindernes_internationale_kampdag\",\n",
    "    \"https://da.wikipedia.org/wiki/Olivia_Levison\",\n",
    "    \"https://da.wikipedia.org/wiki/Lofotenfiskeriets_historie\",\n",
    "    \"https://da.wikipedia.org/wiki/Broder_Rus\",\n",
    "    \"https://da.wikipedia.org/wiki/S%C3%B8ren_Nielsen_May\",\n",
    "    \"https://da.wikipedia.org/wiki/Nerthus\",\n",
    "    \"https://da.wikipedia.org/wiki/Friederich_M%C3%BCnter\",\n",
    "    \"https://da.wikipedia.org/wiki/Den_tavse_mand\",\n",
    "    \"https://da.wikipedia.org/wiki/En_mand_kommer_hjem\",\n",
    "    \"https://da.wikipedia.org/wiki/Orvar-Odd\",\n",
    "    \"https://da.wikipedia.org/wiki/Apollo-programmet\",\n",
    "    \n",
    "    # changed some of them for \"mandfolk\", \"queer\" and \"tøs\" to get correctt # of hits\n",
    "    \"https://da.wikipedia.org/wiki/Et_rigtigt_Mandfolk\", # mandfolk hit\n",
    "    \"https://da.wikipedia.org/wiki/De_dumme_Mandfolk\", # mandfolk hit\n",
    "    \"https://da.wikipedia.org/wiki/Nina_Bang\", # mandfolk hit\n",
    "    \"https://da.wikipedia.org/wiki/Et_Pr%C3%A6riens_Mandfolk\", # mandfolk hit\n",
    "    \"https://da.wikipedia.org/wiki/%C3%85h,_de_mandfolk!\", # mandfolk hit\n",
    "    \"https://da.wikipedia.org/wiki/Olsenbandens_aller_siste_kupp\" # mandfolk hit\n",
    "    \n",
    "    \"https://da.wikipedia.org/wiki/Dan_Levy_(skuespiller)\", # no hit\n",
    "    \"https://da.wikipedia.org/wiki/Heidi_Mortenson\", # no hit\n",
    "    \"https://da.wikipedia.org/wiki/Joe_Lycett\", # no hit\n",
    "    \"https://da.wikipedia.org/wiki/Aidan_Gillen\", # queer hit\n",
    "    \"https://da.wikipedia.org/wiki/P%C3%A6dagogisk_filosofi\", # queer hit\n",
    "    \n",
    "    \"https://da.wikipedia.org/wiki/En_pokkers_T%C3%B8s\",\n",
    "    \"https://da.wikipedia.org/wiki/Last_Friday_Night_(T.G.I.F.)\",\n",
    "    \"https://da.wikipedia.org/wiki/George_J._Folsey\",\n",
    "    \"https://da.wikipedia.org/wiki/To_T%C3%B8ser_Ta%27r_Aff%C3%A6re\",\n",
    "    \"https://da.wikipedia.org/wiki/Anne_Marie_Andersdatter\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there's not enough data, find more webpages\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape from wikipedia\n",
    "\n",
    "1) Search for pages to add (manually selected)\n",
    "2) Scrape these pages using requests and beautifulsoup4\n",
    "3) Concatenate to one big text bank\n",
    "4) Search for word forms in this text bank. Extract the needed number of texts in the correct length.\n",
    "5) Train model on the new dataset and do bias analysis\n",
    "\n",
    "Afterwards, try to do both types of mitigation on the oversampled dataset\n",
    "\n",
    "OR \n",
    "\n",
    "Try to rerun the original model on non-oversampled dataset\n",
    "ASK MANEX!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully scraped the webpage with the title: \"Hemming Hartmann-Petersen\"\n",
      "Successfully scraped the webpage with the title: \"None\"\n",
      "Successfully scraped the webpage with the title: \"Brdr. Gebis\"\n",
      "Successfully scraped the webpage with the title: \"Mogens Wenzel Andreasen\"\n",
      "Successfully scraped the webpage with the title: \"None\"\n",
      "Successfully scraped the webpage with the title: \"We Wanna Be Free\"\n",
      "Successfully scraped the webpage with the title: \"Christian Molbech\"\n",
      "Successfully scraped the webpage with the title: \"Vore Fædres Sønner\"\n",
      "Successfully scraped the webpage with the title: \"Ebbe Skammelsøn\"\n",
      "Successfully scraped the webpage with the title: \"John Green (forfatter)\"\n",
      "Successfully scraped the webpage with the title: \"LUCK.exe\"\n",
      "Successfully scraped the webpage with the title: \"Du Gør Mig\"\n",
      "Successfully scraped the webpage with the title: \"Eleonore Tscherning\"\n",
      "Successfully scraped the webpage with the title: \"Fætter Højben\"\n",
      "Successfully scraped the webpage with the title: \"Min fætter er pirat\"\n",
      "Successfully scraped the webpage with the title: \"Ralf Pittelkow\"\n",
      "Successfully scraped the webpage with the title: \"None\"\n",
      "Successfully scraped the webpage with the title: \"Krig og fred (Shu-bi-dua)\"\n",
      "Successfully scraped the webpage with the title: \"Thora Esche\"\n",
      "Successfully scraped the webpage with the title: \"None\"\n",
      "Successfully scraped the webpage with the title: \"Danske sild (Shu-bi-dua-sang)\"\n",
      "Successfully scraped the webpage with the title: \"Gård fra Pebringe, Sjælland (Frilandsmuseet)\"\n",
      "Successfully scraped the webpage with the title: \"Sophie Caroline af Ostfriesland\"\n",
      "Successfully scraped the webpage with the title: \"Hospital\"\n",
      "Successfully scraped the webpage with the title: \"J.J. Dampe\"\n",
      "Successfully scraped the webpage with the title: \"Manden der drømte at han vågnede\"\n",
      "Successfully scraped the webpage with the title: \"Står på en alpetop\"\n",
      "Successfully scraped the webpage with the title: \"Louis Marcussen\"\n",
      "Successfully scraped the webpage with the title: \"None\"\n",
      "Successfully scraped the webpage with the title: \"Lysets rige\"\n",
      "Successfully scraped the webpage with the title: \"Søsser Krag\"\n",
      "Successfully scraped the webpage with the title: \"None\"\n",
      "Successfully scraped the webpage with the title: \"Germand Gladensvend\"\n",
      "Successfully scraped the webpage with the title: \"Jean-Paul Sartre\"\n",
      "Successfully scraped the webpage with the title: \"Forløsning\"\n",
      "Successfully scraped the webpage with the title: \"Den danske sang er en ung, blond pige\"\n",
      "Successfully scraped the webpage with the title: \"Warehouse9\"\n",
      "Successfully scraped the webpage with the title: \"Babylebbe\"\n",
      "Successfully scraped the webpage with the title: \"Judith Butler\"\n",
      "Successfully scraped the webpage with the title: \"Christian 8.\"\n",
      "Successfully scraped the webpage with the title: \"None\"\n",
      "Successfully scraped the webpage with the title: \"Titte til hinanden\"\n",
      "Successfully scraped the webpage with the title: \"Stephanie León\"\n",
      "Successfully scraped the webpage with the title: \"13 snart 30\"\n",
      "Successfully scraped the webpage with the title: \"Tæt på - live\"\n",
      "Successfully scraped the webpage with the title: \"Der var engang en dreng\"\n",
      "Successfully scraped the webpage with the title: \"Niels Pind og hans dreng\"\n",
      "Successfully scraped the webpage with the title: \"Smukke dreng\"\n",
      "Successfully scraped the webpage with the title: \"Portræt af en dreng\"\n",
      "Successfully scraped the webpage with the title: \"Drengen\"\n",
      "Successfully scraped the webpage with the title: \"Clint Eastwood\"\n",
      "Successfully scraped the webpage with the title: \"Winfield Scott\"\n",
      "Successfully scraped the webpage with the title: \"Sara Blædel\"\n",
      "Successfully scraped the webpage with the title: \"David Firth\"\n",
      "Successfully scraped the webpage with the title: \"Stephen Dorff\"\n",
      "Successfully scraped the webpage with the title: \"Fætter Vims\"\n",
      "Successfully scraped the webpage with the title: \"Fætter Guf\"\n",
      "Successfully scraped the webpage with the title: \"Fætter BR\"\n",
      "Successfully scraped the webpage with the title: \"Agamemnon\"\n",
      "Successfully scraped the webpage with the title: \"Brylluppet mellem kronprinsesse Victoria og Daniel Westling\"\n",
      "Successfully scraped the webpage with the title: \"En nøgen kvinde sætter sit hår foran et spejl\"\n",
      "Successfully scraped the webpage with the title: \"Kvinders valgret\"\n",
      "Successfully scraped the webpage with the title: \"EM i fodbold 2022 (kvinder)\"\n",
      "Successfully scraped the webpage with the title: \"En duft af kvinde\"\n",
      "Successfully scraped the webpage with the title: \"Kvindernes internationale kampdag\"\n",
      "Successfully scraped the webpage with the title: \"Olivia Levison\"\n",
      "Successfully scraped the webpage with the title: \"Lofotenfiskeriets historie\"\n",
      "Successfully scraped the webpage with the title: \"Broder Rus\"\n",
      "Successfully scraped the webpage with the title: \"Søren Nielsen May\"\n",
      "Successfully scraped the webpage with the title: \"Nerthus\"\n",
      "Successfully scraped the webpage with the title: \"Friederich Münter\"\n",
      "Successfully scraped the webpage with the title: \"Den tavse mand\"\n",
      "Successfully scraped the webpage with the title: \"En mand kommer hjem\"\n",
      "Successfully scraped the webpage with the title: \"Orvar-Odd\"\n",
      "Successfully scraped the webpage with the title: \"Apollo-programmet\"\n",
      "Successfully scraped the webpage with the title: \"Sejd\"\n",
      "Successfully scraped the webpage with the title: \"Margrete 1.\"\n",
      "Successfully scraped the webpage with the title: \"Ørkenens Sønner\"\n",
      "Successfully scraped the webpage with the title: \"Andreas Munch\"\n",
      "Successfully scraped the webpage with the title: \"Lofotenfiskeriets historie\"\n",
      "Successfully scraped the webpage with the title: \"LGBT\"\n",
      "Successfully scraped the webpage with the title: \"Genderqueer\"\n",
      "Successfully scraped the webpage with the title: \"Dan Levy (skuespiller)\"\n",
      "Successfully scraped the webpage with the title: \"Heidi Mortenson\"\n",
      "Successfully scraped the webpage with the title: \"Joe Lycett\"\n",
      "Successfully scraped the webpage with the title: \"En pokkers Tøs\"\n",
      "Successfully scraped the webpage with the title: \"Last Friday Night (T.G.I.F.)\"\n",
      "Successfully scraped the webpage with the title: \"George J. Folsey\"\n",
      "Successfully scraped the webpage with the title: \"To Tøser Ta'r Affære\"\n",
      "Successfully scraped the webpage with the title: \"Anne Marie Andersdatter\"\n"
     ]
    }
   ],
   "source": [
    "# scrape webpages\n",
    "passages = []\n",
    "\n",
    "for url in urls:\n",
    "    content = scrape_wiki_text(url)\n",
    "    for passage in content:\n",
    "        passages.append(passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudocode\n",
    "\n",
    "# split passages into sentences\n",
    "# preprocess passage bank\n",
    "\n",
    "# for (lemma, length) in num_nontoxic_to_add\n",
    "    # num_to_add = num_nontoxic_to_add[(lemma, length)]\n",
    "    # map from lemmas to word forms using get_word_forms\n",
    "\n",
    "    # call function that loops through passage bank and outputs n passages where this words occur (find passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test check occurrences \n",
    "# for passage in passages[:9]:\n",
    "#     occurs = False\n",
    "#     for word in passage.split():\n",
    "#         if word == \"bror\":\n",
    "#             occurs = True\n",
    "#     if occurs == True:\n",
    "#         print(\"bror\")\n",
    "#         print(passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test getting word forms \n",
    "# print(\"lemmatized:\", list(identities[identities[\"identity_lemma\"]==\"trans\"][\"lemmatized\"]))\n",
    "# print(\"word forms:\", list(identities[identities[\"identity_lemma\"]==\"trans\"][\"identity_term\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "(True, 2)\n"
     ]
    }
   ],
   "source": [
    "def occurs_in_list(target:str, text_list:List[str], return_idx:bool=False) -> bool:\n",
    "    \"\"\"Checks whether a word occurs in a list of texts/sentences.\"\"\"\n",
    "    for i, text in enumerate(text_list):\n",
    "        if occurs_in_string(target, text):\n",
    "            if return_idx:\n",
    "                return True, i\n",
    "            else:\n",
    "                return True\n",
    "    if return_idx:\n",
    "        return False, None\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "print(occurs_in_list(\"bror\", [\"min søster er stolt\", \"det er hendes mor ikke\"]))\n",
    "print(occurs_in_list(\"bror\", [\"min søster er stolt\", \"det er hendes mor ikke\", \"jeg elsker min bror højt\"], True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "\n",
    "# def find_combination_idxs(lengths:List[int], lower_bound:int, upper_bound:int) -> List[tuple]:\n",
    "#     \"\"\"Find combinations that fall within that the lower and upper bound (range) and returns the indexes. Combinations can vary in size.\"\"\"\n",
    "#     result = []\n",
    "\n",
    "#     for r in range(1, len(lengths)+1): # different size of combinations\n",
    "#         for combo_idxs in combinations(range(len(lengths)), r): # indexes of different combinations of that size\n",
    "#             combo_lengths = [lengths[i] for i in combo_idxs]\n",
    "#             if lower_bound <= sum(combo_lengths) <= upper_bound:\n",
    "#                 result.append(combo_idxs)\n",
    "\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trans', 'transen', 'transerne', 'transerne']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word_forms(lemma:str, identities:pd.DataFrame) -> List[str]:\n",
    "    \"\"\"Get all the word forms of a lemma, which appear in the identities dataframe.\"\"\"\n",
    "    return list(identities[identities[\"identity_lemma\"]==lemma][\"identity_term\"])\n",
    "\n",
    "get_word_forms(\"trans\", identities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test breaking in nested loops\n",
    "# for y in [[1,-1],[2,2,3,2],[3,2,3],[2]]:\n",
    "#     print(\"Y = \", y)\n",
    "#     for x in y:\n",
    "#         print(\"X =\", x)\n",
    "#         if x == 2:\n",
    "#             print(\"                two found\")\n",
    "#             break\n",
    "#         # print(\"!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Det her er en sætning.\n",
      "Det her er endnu en sætning, hihi.\n"
     ]
    }
   ],
   "source": [
    "# test splitting into sentences\n",
    "\n",
    "doc = nlp('Det her er en sætning. Det her er endnu en sætning, hihi.')\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1515/1515 [17:17<00:00,  1.46it/s] \n"
     ]
    }
   ],
   "source": [
    "# split passages into sentences and preprocess\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('danish')\n",
    "passage_bank = []\n",
    "for passage in tqdm(passages):\n",
    "    sentences = []\n",
    "    doc = nlp(passage)\n",
    "    for sent in doc.sents:\n",
    "        clean_sent = utils.preprocess(str(sent), stop_words)\n",
    "        if len(clean_sent) > 0: # don't add empty strings\n",
    "            sentences.append(clean_sent)\n",
    "    passage_bank.append(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1515 text passages\n"
     ]
    }
   ],
   "source": [
    "print(len(passage_bank), \"text passages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['år matematiklærer seminariet nuuk år gymnasielærer stenhus kostskole erne skabe dag kender p radiodirektør leif lønsmanns ord fremsynede modige nok tage unge radiolyttere alvorligt kilde mangler',\n",
       "  'således gennem år blandt radioens mest skattede studieværter kilde mangler',\n",
       "  'lavede musikprogrammer interviewer programserien',\n",
       "  'mellem brødre bror jørgen hartmannpetersen kendt pseudonymet habakuk',\n",
       "  'sammen oboisten waldemar wolsing lavede række radioprogrammer døde komponister himmelske samtaler'],\n",
       " ['mark ung mand bærer stor byrde sorg had',\n",
       "  'mistet ældre bror dansk soldat dræbt afghanistan',\n",
       "  'teenage drenge mark svært ved kontrollere følelser tab drukner hav had ¿mørkhudede fjende¿ tog elskede så højt',\n",
       "  'blændet had nægter åbne andre',\n",
       "  'par måneder senere løber situationen løbsk afghansk dreng mushin starter klasse',\n",
       "  'mark symbol hader så inderligt vise nåde ligesom bror ej heller vist',\n",
       "  'marks indledende forsøg ryste mørke dreng mislykkes mushin interesse konflikter',\n",
       "  'takt mushins pacifisme stiger voldsomheden mark isolerer kammerater',\n",
       "  'mark ved mushin bærer tragisk byrde få fatale konsekvenser begge drenge']]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_passages(passage_bank:List[str], word_list:List[str]) -> List[str]:\n",
    "    \"\"\"Outputs all the passages where any of the words in the word list occur.\n",
    "\n",
    "    Args:\n",
    "        passage_bank (List[str]): list of text passages.\n",
    "        word_list (List[str]): list of words to find in the text passages.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: list of text passages where at least one of the target words appear once.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    \n",
    "    for sentence_list in passage_bank:\n",
    "        for word in word_list:\n",
    "            if occurs_in_list(target=word, text_list=sentence_list):\n",
    "                result.append(sentence_list)\n",
    "                break # don't need to add it twice\n",
    "    \n",
    "    return result\n",
    "\n",
    "find_passages(passage_bank[:9], [\"bror\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://da.wikipedia.org/wiki/Patrick_Spiegelberg\",\n",
    "\"https://da.wikipedia.org/wiki/Oscar_for_bedste_fotografering\",\n",
    "\"https://da.wikipedia.org/wiki/Tekken_(spilserie)\",\n",
    "\"https://da.wikipedia.org/wiki/Oscaruddelingen_1937\",\n",
    "\"https://da.wikipedia.org/wiki/Pretty_Little_Liars\",\n",
    "\"https://da.wikipedia.org/wiki/Lotte_Merete_Andersen\",\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\"https://da.wikipedia.org/wiki/T%C3%A6t_p%C3%A5_-_live\",\n",
    "\"https://da.wikipedia.org/wiki/En_pokkers_T%C3%B8s\",\n",
    "\"https://da.wikipedia.org/wiki/Kate_Walsh\",\n",
    "\"https://da.wikipedia.org/wiki/Jack_Sparrow\",\n",
    "\"https://da.wikipedia.org/wiki/Des_Knaben_Wunderhorn_(Mahler)\",\n",
    "\"https://da.wikipedia.org/wiki/Steen_%26_Stoffer\",\n",
    "\"https://da.wikipedia.org/wiki/Fiktive_personer_i_Lost\",\n",
    "\"https://da.wikipedia.org/wiki/Nis_Petersen\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully scraped the webpage with the title: \"Tæt på - live\"\n",
      "Successfully scraped the webpage with the title: \"En pokkers Tøs\"\n",
      "Successfully scraped the webpage with the title: \"Kate Walsh\"\n",
      "Successfully scraped the webpage with the title: \"Jack Sparrow\"\n",
      "Successfully scraped the webpage with the title: \"Des Knaben Wunderhorn (Mahler)\"\n",
      "Successfully scraped the webpage with the title: \"Steen & Stoffer\"\n",
      "Successfully scraped the webpage with the title: \"Fiktive personer i Lost\"\n",
      "Successfully scraped the webpage with the title: \"Nis Petersen\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [01:39<00:00,  2.32it/s]\n"
     ]
    }
   ],
   "source": [
    "passages = []\n",
    "\n",
    "for url in urls:\n",
    "    content = scrape_wiki_text(url)\n",
    "    for passage in content:\n",
    "        passages.append(passage)\n",
    "\n",
    "# split passages into sentences and preprocess\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('danish')\n",
    "passage_bank = []\n",
    "for passage in tqdm(passages):\n",
    "    sentences = []\n",
    "    try:\n",
    "        doc = nlp(passage)\n",
    "        for sent in doc.sents:\n",
    "            clean_sent = utils.preprocess(str(sent), stop_words)\n",
    "            if len(clean_sent) > 0: # don't add empty strings\n",
    "                sentences.append(clean_sent)\n",
    "        passage_bank.append(sentences)\n",
    "    except:\n",
    "        print(\"EXCEPT\", passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potential: 8\n",
      "51 faktisk lige siden ung tøs så nirvana unplugged mtv\n",
      "45 pokkers tøs amerikansk stumfilm edwin stevens\n",
      "31 tror virkelig bare tøser elsker\n",
      "54 jack sparrow kaptajn onde tøs senere kendt sorte perle\n",
      "71 beckett gav ordre onde tøs brændes sænkes brændte p pirat jacks håndled\n",
      "59 pigen forsøger indsmigre unge mand svar naragtige tøs gider\n",
      "58 dansk avis oversat kast – knus slimede tøser kilde mangler\n",
      "40 spøg kaldet the french chick franske tøs\n",
      "14 saadan tøs kit\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "new_examples = []\n",
    "\n",
    "for (lemma, length) in {(\"tøs\", \"0-19\"):7}: #tqdm(num_nontoxic_to_add): # for each lemma and length we need to deal with\n",
    "\n",
    "    # range (length bucket)\n",
    "    length_range = length.split(\"-\")\n",
    "    length_range = [int(l) for l in length_range]\n",
    "    length_range[1] = 59\n",
    "\n",
    "    # number of nontoxic examples to add\n",
    "    num_to_add = num_nontoxic_to_add[(lemma, length)] # number new nontoxic to add\n",
    "\n",
    "    # word forms\n",
    "    word_list = get_word_forms(lemma, identities) # word forms\n",
    "\n",
    "    # find passages that the words appear in\n",
    "    passages = find_passages(passage_bank, word_list)\n",
    "    \n",
    "    # initialize variables\n",
    "    num_added = 0\n",
    "    \n",
    "    print(\"potential:\", len(passages))\n",
    "\n",
    "    for passage in passages: # for each passage where the lemma appears\n",
    "        \n",
    "        if num_added < num_to_add: # only continue if we still need to add more sentences          \n",
    "            sentence_lengths = [len(sent)+1 for sent in passage] # +1 = space between sentences\n",
    "            \n",
    "            # if the full passage is within range, add that\n",
    "            if length_range[0] <= len(' '.join(passage)) <= length_range[1]:\n",
    "                #print(type(passage), passage)\n",
    "                new_examples.append(' '.join(passage))\n",
    "                num_added += 1\n",
    "                print(len(' '.join(passage)), ' '.join(passage))\n",
    "\n",
    "            else:\n",
    "                for sentence in passage:\n",
    "                    if any(occurs_in_string(word, sentence) for word in word_list):\n",
    "                        if length_range[0] <= len(sentence) <= length_range[1]:\n",
    "                            new_examples.append(sentence)\n",
    "                            num_added += 1\n",
    "                        print(len(sentence), sentence)\n",
    "    \n",
    "    if num_added < num_to_add:\n",
    "        print(lemma, length_range, num_to_add)\n",
    "        print(num_added, num_to_add)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 hits\n",
    "\"https://da.wikipedia.org/wiki/T%C3%A6t_p%C3%A5_-_live\",\n",
    "\"https://da.wikipedia.org/wiki/En_pokkers_T%C3%B8s\",\n",
    "\"https://da.wikipedia.org/wiki/Kate_Walsh\",\n",
    "\"https://da.wikipedia.org/wiki/Jack_Sparrow\",\n",
    "\"https://da.wikipedia.org/wiki/Des_Knaben_Wunderhorn_(Mahler)\",\n",
    "\"https://da.wikipedia.org/wiki/Steen_%26_Stoffer\",\n",
    "\"https://da.wikipedia.org/wiki/Fiktive_personer_i_Lost\",\n",
    "\"https://da.wikipedia.org/wiki/Nis_Petersen\"\n",
    "\n",
    "# maybe\n",
    "# \"https://da.wikipedia.org/wiki/En_gang\"\n",
    "# \"https://da.wikipedia.org/wiki/Dominans_(sexologi)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 44.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mandfolk [20, 59] 7\n",
      "1 7\n",
      "\n",
      "queer [620, 3519] 2\n",
      "0 2\n",
      "\n",
      "tøs [0, 19] 8\n",
      "0 8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "new_examples = []\n",
    "\n",
    "for (lemma, length) in tqdm(num_nontoxic_to_add): # for each lemma and length we need to deal with\n",
    "\n",
    "    # range (length bucket)\n",
    "    length_range = length.split(\"-\")\n",
    "    length_range = [int(l) for l in length_range]\n",
    "\n",
    "    # number of nontoxic examples to add\n",
    "    num_to_add = num_nontoxic_to_add[(lemma, length)] # number new nontoxic to add\n",
    "\n",
    "    # word forms\n",
    "    word_list = get_word_forms(lemma, identities) # word forms\n",
    "\n",
    "    # find passages that the words appear in\n",
    "    passages = find_passages(passage_bank, word_list)\n",
    "    \n",
    "    # initialize variables\n",
    "    num_added = 0\n",
    "\n",
    "    for passage in passages: # for each passage where the lemma appears\n",
    "        \n",
    "        if num_added < num_to_add: # only continue if we still need to add more sentences          \n",
    "            sentence_lengths = [len(sent)+1 for sent in passage] # +1 = space between sentences\n",
    "            \n",
    "            # if the full passage is within range, add that\n",
    "            if length_range[0] <= len(' '.join(passage)) <= length_range[1]:\n",
    "                #print(type(passage), passage)\n",
    "                new_examples.append(' '.join(passage))\n",
    "                num_added += 1\n",
    "\n",
    "            else:\n",
    "                for sentence in passage:\n",
    "                    if any(occurs_in_string(word, sentence) for word in word_list):\n",
    "                        if length_range[0] <= len(sentence) <= length_range[1]:\n",
    "                            new_examples.append(sentence)\n",
    "                            num_added += 1\n",
    "    \n",
    "    if num_added < num_to_add:\n",
    "        print(lemma, length_range, num_to_add)\n",
    "        print(num_added, num_to_add)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['molbech født opvokset molbechs hus fars tjenestebolig ved akademiet sorø christian søn norske hovmester matematiklærer sorø akademi johan christian molbech tyske louise philippine friderica tübel datter musiker komponist christian gottlieb tübel blankenburg barndomshjemmet trods fine hus farens stilling præget fattigdom psykisk lidelse christians mor led psykisk sygdom arrige anfald tog opium dæmpe anfaldene udgifterne morens opium ruinerede familiens økonomi farens beskedne løn rakte knap nok børn faren tog tilflugt familieproblemerne violinspil havedyrkning morens psykiske sygdom arvet christians yngre bror teologen carl fredrik m led blandt andet depression andre efterkommere christian led svag psykisk helbred voksenlivet berygtet stridighed hidsighed nævnt flere biografier bakkehuset endda øgenavnet ulven pga dårlige temperament',\n",
       " 'dreng dansk dokumentarfilm instrueret julie bezzera madsen',\n",
       " 'oliver dreng år fanget egen krop',\n",
       " 'indeni føler dreng udenpå pige',\n",
       " 'niels pind dreng dansk film',\n",
       " 'smukke dreng dansk dramafilm',\n",
       " 'dreng sort hud ser direkte beskueren',\n",
       " 'filmens hovedperson mads årig velbegavet dreng',\n",
       " 'christian år faren sende skib familiemedlem danskindisk koloni serampore så christian udlært handel få god karriere drengen så syg hjemve aldrig nåede længere helsingør skibet vendte hjem',\n",
       " 'generationskløften altid eksisteret næsten skræve far opvækst andet land født danmark ægte kultursammenstød familiens skød kan bygges bro mellem generationerne værktøjerne hedder kærlighed respekt',\n",
       " 'betragtede aldersforskellen stor nød desuden tilværelse ungkarl største forhindring øjne formentlig år omfattet fjendskab officerskorps far ledende medlem',\n",
       " 'sartres mor kusine albert schweitzer far charles schweitzer ældre bror albert schweitzers far louis théophile sartre omtalte – upræcist onkel al',\n",
       " 'luckexe handler ung fyr kenneth uheldig svært ved snakke pigen forelsket',\n",
       " 'eastwood senere udtalt forvandling tvwesternhelt helten nævefuld dollars rawhide forfærdelig træt rollen konventionelle pæne fyr',\n",
       " 'andet eksempel scotts forfængelighed reaktion tabe spil skak ung fyr new orleans ved navn paul morphy',\n",
       " 'camillas nysgerrighed fanges derimod ung fyr halvt år tidligere døde',\n",
       " 'devvo ung fyr kommer doncasterhullområdet england nærheden sheffield york',\n",
       " 'rapkæftet fyr oftest set beruset tilstand ude lede folk større kan starte slagsmål',\n",
       " 'eleonore gift år ældre fætter tscherning maleriet kom efterhånden fylde mindre mest fordi husholdning selskabelige forpligtelser kom fylde liv',\n",
       " 'fætter højben engelsk gladstone gander anders ands heldige fætter første gang set historien kæphøje krystere wintertime wager januar smide anders hus grund væddemål trods familieforhold højben ifølge engelske navn gladstone gander slet and gase enkelt gang første danske årgang kaldt fætter erik',\n",
       " 'søn kong christian s halvbroder arveprins frederik b tilhørte oldenborgske slægt fætter frederik efterlod legitime sønner arveprinsens søn christian frederik ifølge kongeloven nærmeste arving tronen ved frederik s død',\n",
       " 'faddere farbror kong christian farmor enkedronning juliane marie gudmor bar prinsen dåben fætter kronprins frederik kusine prinsesse louise augusta hertug frederik christian augustenborg',\n",
       " 'oprindelig engangsfigur historien fætter vims kommer besøg trykt anders and co greb læserne begejstring tilbagevendende figur flere historier plagede livet fætter anders kat tommy',\n",
       " 'nasib farah år bor odense sammen danske kone tre små børn barndomsegn somalia dag udgangspunkt storstilet pirateri mest hårdkogte pirater kommer nasibs egen klan familie nasib hører fætter somalia abdi planer slutte piraterne beslutter rejse hjem få fætteren ændre mening nasibs argumenter kun ringe vægt abdis alternativer fremtid fortaber tåge borgerkrig korruption khattyggeri',\n",
       " 'pittelkow student sønderborg statsskole magart litteraturvidenskab københavns universitet adjunkt lektor ved institut litteraturvidenskab københavns universitet år frem slutningen politisk kommentator morgenavisen jyllandsposten mellem ligeledes tilknyttet kommentator tv tiden jyllands posten ansvarshavende redaktør bloggen korte avis stiftede kone journalist tidl minister karen jespersen',\n",
       " 'dagligstuen kan gå etfagskøkken meste rummet består mægtige skorstens bundparti ildstedets type placering karakteriserer hustypen ” ovnhus ” skorstenshammeren egetræ indskåret forbogstaverne kps eis samt anno året køkkenet renoveret arnebænken står trefødder skorstenen hænger kedelkrogen gryder sammen lysekællingen gav lys skorstenen så konen se skinker pølser hang rygning skorstenen indfyring bageovnen bageovnen oprindeligt genopført frilandsmuseet skyldes ovnen fjernet museet erhvervede gården museet ønskede vise gården tilføjelser ændringer uden bageovn ’ erne rettet ved rekonstruere bageovn oplysninger udgravningerne forbindelse nedtagningen gården',\n",
       " 'november åbnede magdalenehjemmet ejendom jagtvej hjemmet rettes kvinder alderen endt prostitution ønskede komme',\n",
       " 'sideløbende magdalenehjemmet engagerede thora esche spørgsmålet ophævelse ved lov regulerede prostitution få oprettet nye steder kvinder underlagt lovgivning førte oprettelse nyt hjem skovly ved vedbæk',\n",
       " 'ganske vist hyldes danske kvinder samtidigt afsløres mændenes syn kvinderne forskelligheden ved to køn tænker baller lår nødder negle tænder hår må godt smukke imens falder jeres intelligens',\n",
       " 'beauvoir skræmt forestående adskillelse især fordi sartre ejes nogen snydes tilfældige oplevelser andre kvinder beauvoirs kærlighed hinanden alligevel vare livet mente fordi tvillingsjæle',\n",
       " 'bogens første del problematiserer ideen kvinden feminismens omdrejningspunkt netop fordi begrebet kvinde dækker heterogen gruppe kønsroller seksualiteter',\n",
       " 'kongens elskerinder elise ahlefeldtlaurvig johanne marie brandvold eide bügel johanne buchwaldt amalie jensen mathilde winding sophie frederikke kraft derudover række kvinder nævnt initialer kongens dagbøger kun tilfælde kom børn kan sikker kongens forhold seksuel art',\n",
       " 'mand syv kvinder kom plakaterne instrueret don siegel eastwood stor indflydelse handlingen blandt andet scenen får amputeret ben fører afgår ved døden slutningen filmen filmen fik premiere april publikumsmæssigt fiasko',\n",
       " 'ung kvinde anmelder voldtægt kriminalassistent louise rick får sagen hurtigt går louise eneste offer andet offer findes kvalt efterhånden efterforskningen gang dukker flere ofrer dybe ar sjælen louise rick sætter voldtægtmanden søgelys få frem skjul',\n",
       " 'musikalsk ansvarlige organisten gustaf sjökvist ansvarlig musikken ved brylluppet originale bryllupsmusik komponeret karin rehnqvist første kvinde nogensinde komponere musik kongeligt bryllup',\n",
       " 'endelig poul ekelunds maleri stående figur kvinde set ryggen figur viser stærk inspiration eckersbergs maleri ekelunds maleri indgår statens museum kunsts samling',\n",
       " 'april ændredes valgloven så kvinder fik stemmeret kommunalvalg året marts fire dage fejrede kvindedagen første gang usa deltog kvinder første gang kommunalt valg danmark grundlovsændringen trådte kraft gav kvinder stemmeret valgbarhed folke landstingsvalg',\n",
       " 'folketingsvalget afholdt april første grundlovsreformen udvidede folketinget udvidet pladser mere fordoblede antallet vælgere ved give kvinder stemmeret valgbarhed',\n",
       " 'hjemmebanefavoritten england vandt emturneringen –sejr tyskland finalen samtidig slog rekord flest tilskuere emkamp nogensinde både mænd kvinder england gik igennem turneringen seks sejre nederlag målscore –',\n",
       " 'duft kvinde modtaget positivt anmelderne særligt pacino fik rosende ord filmen rating positive tilkendegivelser filmhjemmesiden rotten tomatoes metascore baseret anmeldelser',\n",
       " 'stuen indrettet sædvanligt midtsjælland langbord bænk langs vinduesvæggen par omhængsenge ved nordre væg gåsebænken mændene plads rang husbond bordendebænken kvindfolkene stod gammel sæd skik spiste ved ydersiden bordet bænkekrogen stod tobakskassen ølkanden mens klukflasken indeholde hel pot brændevin gemtes hængeskabet væggene ses udskårne bemalede paneler både ældste nyklassicistiske omkring sidst tilkomne krogen står standur slutningen årene senere egetræsådring ligesom hængeskabet',\n",
       " 'stadig mere pengebaseret økonomi fiskerbønderne behov kontanter mindst købe basisvarer producere ting skatter afgifter pålagt betale penge lofotenfiskeriet derfor vigtigste pengeindkomst få husholdningen nå balance fornuftig brug arbejdskraften karene drog lofoten tid året ellers muligt kvinder barn ældre håndtere gårdarbejde distriktslægen steigen udtalte slutningen tallet kvindfolkene holde mændene hjemme helt vidste lofotenfiskeriet så godt give udbytte gårdkone svarede herpå n år nytaar hverken nytte opbyggels ved mandfolkene ro nogen ting bare ræker dørene saa kan ligesaa godt borte',\n",
       " 'christian tosproget siden barndommen mor livet igennem talte skrev tysk både mand børn christian skrev breve tysk',\n",
       " 'sidst videoen ser så uventet finder kæreste selskab mand smidt',\n",
       " 'eleonore tscherning tidligt klar mand offentligheden – danmarkshistorien – fik status historisk person fænomen',\n",
       " 'kvinde fortiden ser mand fremtiden fantaserer engang følger ender tid',\n",
       " 'shubidua viser humor begæret kan holdes tilbage mændene forsøger hyldest kvindernes præmisser',\n",
       " 'datter sidse overtog gården sammen mand jens larsen omkring søn clemmen jensen overtog arvefæster sammen kone maren',\n",
       " 'varmt lys olielampen bordet syslede både mænd kvinder arbejder',\n",
       " 'forfatningsmæssige idéer efterhånden virkeliggjort grundloven næsten identisk kæmpet nye tids mænd overså helt',\n",
       " 'manden drømte vågnede dansk kortfilm instrueret åke sandgren eget manuskript',\n",
       " 'nået toppen mor brrr skidekoldt ja nået toppen mor må stolt manden trives øverste trin hva faen sku egentlig spørger frustreret',\n",
       " 'modsiger viderebygger freuds påstand lesbiske kvinder bygger kønsroller efterligne mænd',\n",
       " 'ukendt halvnøgen mand træder badeværelse bange griber taske jakke sko løber gaden kvinde står skynder',\n",
       " 'sangen handler ifølge medina søde jalousi kan gå rundt mænd partner',\n",
       " 'yngre fremmedartet elegant klædt mand stiger perronen par kufferter masse flotte mærker fremmede lande',\n",
       " 'film fik eastwood gennembrud skuespiller hovedrollen manden uden navn',\n",
       " 'eastwood medvirkede derfor skabe figuren manden uden navn give særlige karakterpræg',\n",
       " 'manden uden navn nyskabelse inden genren moralske tvetydighed givet betegnelsen antihelt',\n",
       " 'filmen ret brutal western eastwood spiller rollen mand overlever hængning derefter søger hævn fjender',\n",
       " 'tidspunkt begyndte prikke hul hårdkogte image fået manden uden navn dirty harry',\n",
       " 'eastwoods næste projekt således instruktionen hed breezy film kærlighedsaffære mellem midaldrende mand teenagepige',\n",
       " 'eastwood bemærket lockes talent fik kay lenz hovedrollen breezy william holden spillede rollen midaldrende mand',\n",
       " 'roger ebert sammenlignede styrken eastwoods portræt josey wales mand uden navn leones trilogi roste filmens atmosfære',\n",
       " 'længst svunden tid pioneren ensomt arbejdende mand kæmper kamp uden anerkendt samfundet',\n",
       " 'western kan forestille jesus engang manden alene hesteryg derude ingen endnu ødelagt naturen',\n",
       " 'sammen ven spillet morgan freeman påtager straffe mand skamferet prostitueret',\n",
       " 'eastwood spillet hovedrollen to filmserier manden uden navn dollarstrilogien harry callahan dirty harryserien',\n",
       " 'louise rick ringet midt afhøring ung kvinde lige fået dræbt mand',\n",
       " 'politikommissær dea vice politiinspektør liam kontaktet charlottes mand charlotte forsvundet nærheden hjem tommerup fyn',\n",
       " 'trojanske krig mand væk ti år indledte affære agamemnons fætter aigisthos',\n",
       " 'kendetegn ved kønsdelt arbejdsdeling mændene drev fiskeri fangst mens kvinderne ansvar dyr stalde husholdning børn',\n",
       " 'egils saga fortæller egentlig økonomisk system fiskebønder organisering høvding udstyrede sendte mænd fiskeri fangst',\n",
       " 'kaldt redistributive system blot frie mænd arbejdsfolk drenge leilendinger fæstebønder sandsynligvis trælle sendt fiskeri',\n",
       " 'kendetegnende bee gees desuden høje falsetstemmer shubidua efterligner omtaler nummeret igen store stærke mænd lyder drengekor bethlehem brdr gebis tager høje fis kan lave musik lyder prik nøgen grease gris rammes elastik brdr gebis tager høje fis',\n",
       " 'sammen mand begravet garnisons kirkegård alderdom tscherning taget forbehold kristendommen ønskede ingen traditionel kirkelig begravelse ligbrænding ved død endnu tilladt danmark delikat emne eget ønske derfor først ligbrændt göteborg før urne nedsat samme gravsted ægtefællen',\n",
       " 'lasse succesrig mand smukke kone karin gravid første barn tabloidavisen deadlines stjernefotograf altid pletten sker derfor reder ene forside hjem lasses succes skyldes høj grad lyssky samarbejde politibetjenten martin martin suspenderes succesen pludselig fare',\n",
       " 'dampe flyttede straks hovedstaden boede sandsynligvis børn indtil senere kom finansloven forfatningsmæssige idéer efterhånden virkeliggjort grundloven næsten identisk kæmpet nye tids mænd overså helt døde ubemærket kommunehospitalet nekrolog indskrænkede få linjer københavns aviser',\n",
       " 'melodien taget seals and crofts ernummer standin on a mountain top sangen handler yngre mand kraftigt tilskyndet mor steget helt tops karrieren',\n",
       " 'teksten dobbelttydig ved ene side handle stræberi arbejdslivet side kan forstås helt bogstaveligt mand besteget tinde alperne mærker ensomheden kulden bjergtoppen',\n",
       " 'sammen tilbragte to år ved lycée louislegrand forberedelse fire år ved école normale supérieure frankrigs mest prestigefyldte institut kun mænd',\n",
       " 'eastwood brød igennem westernskuespiller erne tvserien rawhide slog alvor igennem manden uden navn sergio leones spaghettiwesternfilm dollartrilogien erne herefter antihelten harry callahan fem dirty harryfilm erne erne',\n",
       " 'mand syv kvinder kom plakaterne instrueret don siegel eastwood stor indflydelse handlingen blandt andet scenen får amputeret ben fører afgår ved døden slutningen filmen filmen fik premiere april publikumsmæssigt fiasko',\n",
       " 'filmen blevet beskrevet dyster western sætter fokus grimmere aspekter vold myten gamle vesten blandt andet scene ung fyr sluttet munny dræber mand mens wc',\n",
       " 'asterix obelix godt regnet svært gøre mandfolk',\n",
       " 'christian tosproget siden barndommen mor livet igennem talte skrev tysk både mand børn christian skrev breve tysk',\n",
       " 'følger kvæste far alvorligt hugge hånden mor inden ifølge tilbagevendende omkvæd går landflygtighed',\n",
       " 'nået toppen mor brrr skidekoldt ja nået toppen mor må stolt manden trives øverste trin hva faen sku egentlig spørger frustreret',\n",
       " 'mor indgået aftale støtte datteren ægteparret bente peter poulsen datter gået skole søsser krag',\n",
       " 'eneste lyspunkt carlos smukke pige camina forelsker senere danner par',\n",
       " 'ungdomsromanen handler colin singleton sytten år gammel anagramelskende dreng sammen så vidt husker blevet dumpet piger ved navn katherine',\n",
       " 'margo pige længe følt paper girl paper town sidste eventyr q stikker venner familie',\n",
       " 'the fault in our stars handler hazel grace lancaster årig pige kræft skjoldbruskkirtlen spredt lunger',\n",
       " 'christian søn norske hovmester matematiklærer sorø akademi johan christian molbech tyske louise philippine friderica tübel datter musiker komponist christian gottlieb tübel blankenburg',\n",
       " 'visen grum historie kongepar sejlads oplever holdt fast trold gam lover få videre give dronningen bæltet smider nøgle overbord kommer videre tilbage land opdager gravid fem måneder senere føder søn bedrøvet ser vokse idet indser trolden trolden kommer besøg prøver bilde nogen børn',\n",
       " 'danske strygekvartet indspillede instrumentaludgave bassisten thomas fonnesbech pianisten søren møller oboisten max artved arrangement peter jensen album sletternes sønner',\n",
       " 'søn kong christian s halvbroder arveprins frederik b tilhørte oldenborgske slægt fætter frederik efterlod legitime sønner arveprinsens søn christian frederik ifølge kongeloven nærmeste arving tronen ved frederik s død',\n",
       " 'christian uægte børn deriblandt frederik carl eide jens jørgensen fremført teori eventyrdigteren hc andersen søn christian rolf dorset udgivet bogen paradisbarnet hævder samme bestridt flere']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# afterwards, run code with balances again and see if its closer to prior distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if any(occurs_in_string(word, \"hej det her er mig\") for word in [\"være\", \"er\"]):\n",
    "#     print(\"OK\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
