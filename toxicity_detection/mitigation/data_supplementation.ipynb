{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Supplementation (suppl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method\n",
    "1.\tIdentify identity terms with the most disproportionate data distributions \n",
    "    1. Stem/lemmatize dataset\n",
    "    2. For each lemma in the synthetic test set:\n",
    "        1. Check distribution across labels in dataset, i.e. difference between frequency in toxic comments and overall\n",
    "        2.\tAlso check length differences!\n",
    "    3. What does this mean exactly? \n",
    "        1.\t“Identity terms affected by the false positive bias are disproportionately used in toxic comments in our training data. For example, the word ‘gay’ appears in 3% of toxic comments but only 0.5% of comments overall.”\n",
    "        2.\tFrequency of identity terms in toxic comments and overall: \n",
    "2.\tAdd additional non-toxic examples that contain the identity terms that appear disproportionately across labels in the original dataset\n",
    "    1.\tUse wiki data – assumed to be non-toxic\n",
    "    2.\tAdd enough so that the balance is in line with the prior distribution for the overall dataset\n",
    "        1.\tE.g. until % “gay” in toxic comment is close to 0.50% as in overall data.\n",
    "3.\tMaybe consider different lengths as CNNs could be sensitive to this\n",
    "    1.\t“toxic comments tend to be shorter” (Dixon et al. 2018)\n",
    "4.\tSupposed to reduce false positives. Could also do the opposite? But more difficult to find toxic comments unless we take them from places that are supposedly toxic (e.g. “roast me”)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\love2\\anaconda3\\envs\\thesis2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# set cwd\n",
    "import os\n",
    "os.chdir(\"g:\\\\My Drive\\\\ITC, 5th semester (Thesis)\\\\Code\\\\Github_code\\\\toxicity_detection\")\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "# from random import choice, choices\n",
    "# from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "# from string import punctuation\n",
    "# # import spacy\n",
    "from spacy import displacy\n",
    "from tqdm import tqdm\n",
    "from utils import load_dkhate\n",
    "# from typing import Dict\n",
    "import pickle\n",
    "import dacy\n",
    "# import utils\n",
    "# import nltk\n",
    "# import re\n",
    "# import string\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text:str) -> str:\n",
    "    \"\"\"Returns a lemmatized version of the text or itself if the string is empty.\"\"\"\n",
    "    if len(text) > 0:\n",
    "        doc = nlp(text)\n",
    "        lemmas = [token.lemma_ for token in doc]\n",
    "        lemmatized_text = \" \".join(lemmas)\n",
    "        return lemmatized_text\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def occurs_in(target, text):\n",
    "    \"\"\"Checks whether a word occurs in a text.\"\"\"\n",
    "    for word in text.split():\n",
    "        if word == target:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DaCy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load daCy model (medium works fine)\n",
    "nlp = dacy.load(\"da_dacy_medium_trf-0.2.0\") # takes around 4 minutes the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token     \tLemma\t\tPOS-tag\t\tEntity type\n",
      "Mit       :\tMit       \tDET\t\t\n",
      "navn      :\tnavn      \tNOUN\t\t\n",
      "er        :\tvære      \tAUX\t\t\n",
      "Maja      :\tMaja      \tPROPN\t\tPER\n",
      ".         :\t.         \tPUNCT\t\t\n",
      "Jeg       :\tjeg       \tPRON\t\t\n",
      "bor       :\tbo        \tVERB\t\t\n",
      "på        :\tpå        \tADP\t\t\n",
      "Bispebjerg:\tBispebjerg\tPROPN\t\tLOC\n",
      ",         :\t,         \tPUNCT\t\t\n",
      "men       :\tmen       \tCCONJ\t\t\n",
      "er        :\tvære      \tVERB\t\t\n",
      "fra       :\tfra       \tADP\t\t\n",
      "Næstved   :\tNæstved   \tPROPN\t\tLOC\n",
      ".         :\t.         \tPUNCT\t\t\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mit navn er \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Maja\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER\n",
       " <a style=\"text-decoration: none; color: inherit; font-weight: normal\" href=\"#\">Q18184581</a>\n",
       "</span>\n",
       "</mark>\n",
       ". Jeg bor på \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bispebjerg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC\n",
       " <a style=\"text-decoration: none; color: inherit; font-weight: normal\" href=\"#\">NIL</a>\n",
       "</span>\n",
       "</mark>\n",
       ", men er fra \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Næstved\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC\n",
       " <a style=\"text-decoration: none; color: inherit; font-weight: normal\" href=\"#\">Q21178</a>\n",
       "</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test that it works as expected \n",
    "doc = nlp(\"Mit navn er Maja. Jeg bor på Bispebjerg, men er fra Næstved.\") \n",
    "print(\"Token     \\tLemma\\t\\tPOS-tag\\t\\tEntity type\")\n",
    "for tok in doc: \n",
    "    print(f\"{str(tok).ljust(10)}:\\t{str(tok.lemma_).ljust(10)}\\t{tok.pos_}\\t\\t{tok.ent_type_}\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>hørt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>reaktion svensker</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>hey champ smide link ser hearthstone henne</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>melder vold voldtægt viser sandt beviser diver...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>betaler omkring mb kb får nok tættere kb kb be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet label\n",
       "id                                                           \n",
       "2378                                               hørt     0\n",
       "1879                                  reaktion svensker     0\n",
       "42           hey champ smide link ser hearthstone henne     0\n",
       "457   melder vold voldtægt viser sandt beviser diver...     1\n",
       "3108  betaler omkring mb kb får nok tættere kb kb be...     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data splits \n",
    "_, _, y_train_orig, _ = load_dkhate(test_size=0.2)\n",
    "with open(os.getcwd()+\"/data/X_orig_preproc.pkl\", \"rb\") as f:\n",
    "    content = pickle.load(f)\n",
    "\n",
    "X_train_orig = content[\"X_train\"]\n",
    "train_orig = pd.DataFrame([X_train_orig, y_train_orig]).T\n",
    "train_orig.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2631/2631 [05:56<00:00,  7.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# lemmatize the texts\n",
    "train_orig[\"lemmas\"] = train_orig[\"tweet\"].progress_apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1174    scanne lortet pc markere tage underskrift ny d...\n",
       "3301    kunne klarer fyr stort se venn vej samme spor ...\n",
       "1390    fuck meget sol varme lille regn please dansk å...\n",
       "799     hvorfor fucking stor helvede fejre kristn hell...\n",
       "900     ingen udlænding ved grænse heller kriminell ku...\n",
       "Name: lemmas, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into toxic, non-toxic and all\n",
    "toxic_text = train_orig[train_orig[\"label\"] == 1][\"lemmas\"]\n",
    "nontoxic_text = train_orig[train_orig[\"label\"] == 0][\"lemmas\"]\n",
    "all_text =  train_orig[\"lemmas\"]\n",
    "\n",
    "NUM_TOXIC = len(toxic_text)\n",
    "NUM_NONTOXIC = len(nontoxic_text)\n",
    "NUM_TOTAL = len(all_text)\n",
    "\n",
    "toxic_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load identity terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 unique identity lemmas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity_term</th>\n",
       "      <th>identity_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>transpersonerne</td>\n",
       "      <td>transperson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>transvestitterne</td>\n",
       "      <td>transvestit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>transerne</td>\n",
       "      <td>trans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>androgynerne</td>\n",
       "      <td>androgyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>hermafroditterne</td>\n",
       "      <td>hermafrodit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        identity_term identity_lemma\n",
       "155   transpersonerne    transperson\n",
       "156  transvestitterne    transvestit\n",
       "157         transerne          trans\n",
       "158      androgynerne       androgyn\n",
       "159  hermafroditterne    hermafrodit"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load identity terms\n",
    "identities = pd.read_excel(os.getcwd()+\"/data/identity_terms.xlsx\")\n",
    "print(len(set(identities[\"identity_lemma\"])), \"unique identity lemmas\")\n",
    "identities.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:08<00:00, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 unique lemmatized identity terms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity_term</th>\n",
       "      <th>identity_lemma</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>transpersonerne</td>\n",
       "      <td>transperson</td>\n",
       "      <td>transperson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>transvestitterne</td>\n",
       "      <td>transvestit</td>\n",
       "      <td>transvestitterne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>transerne</td>\n",
       "      <td>trans</td>\n",
       "      <td>transe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>androgynerne</td>\n",
       "      <td>androgyn</td>\n",
       "      <td>androgynerne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>hermafroditterne</td>\n",
       "      <td>hermafrodit</td>\n",
       "      <td>hermafroditterne</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        identity_term identity_lemma        lemmatized\n",
       "155   transpersonerne    transperson       transperson\n",
       "156  transvestitterne    transvestit  transvestitterne\n",
       "157         transerne          trans            transe\n",
       "158      androgynerne       androgyn      androgynerne\n",
       "159  hermafroditterne    hermafrodit  hermafroditterne"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatize the identity terms\n",
    "identities[\"lemmatized\"] = identities[\"identity_term\"].progress_apply(lemmatize_text)\n",
    "print(len(set(identities[\"lemmatized\"])), \"unique lemmatized identity terms\")\n",
    "identities.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map from lemmatized word to the actual lemma\n",
    "lemmatized_2_lemma = dict(zip(identities[\"lemmatized\"], identities[\"identity_lemma\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Data Supplemenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of identity terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should return False. Result: 0\n",
      "This should return True.  Result: 1\n"
     ]
    }
   ],
   "source": [
    "# test function\n",
    "print(\"This should return False. Result:\", occurs_in(\"mor\", \"elsker din humor\"))\n",
    "print(\"This should return True.  Result:\", occurs_in(\"mor\", \"hans mor er pænt sød\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many texts these terms occur in\n",
    "lemmatized_identities = list(set(identities[\"lemmatized\"]))\n",
    "occur_in_n_texts = {\"lemmatized_identity\": lemmatized_identities, \"toxic_count\": [], \"nontoxic_count\":[], \"total_count\":[]}\n",
    "\n",
    "for lemma in lemmatized_identities:\n",
    "    occur_in_n_texts[\"toxic_count\"].append(toxic_text.apply(lambda x: occurs_in(target=lemma, text=x)).sum())\n",
    "    occur_in_n_texts[\"nontoxic_count\"].append(nontoxic_text.apply(lambda x: occurs_in(target=lemma, text=x)).sum())\n",
    "    occur_in_n_texts[\"total_count\"].append(all_text.apply(lambda x: occurs_in(target=lemma, text=x)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>toxic_count</th>\n",
       "      <th>nontoxic_count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>toxic_pct</th>\n",
       "      <th>nontoxic_pct</th>\n",
       "      <th>total_pct</th>\n",
       "      <th>tox_total_diff</th>\n",
       "      <th>tox_total_abs_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mand</td>\n",
       "      <td>16</td>\n",
       "      <td>57</td>\n",
       "      <td>73</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kvinde</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>33</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fyr</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mandfolk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kvindfolk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tøs</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>søn</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fætter</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kone</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mor</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>far</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>dreng</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>kusine</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>søster</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>herre</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>pige</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>bror</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>datter</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>dame</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lemma  toxic_count  nontoxic_count  total_count  toxic_pct  \\\n",
       "0        mand           16              57           73       4.60   \n",
       "1      kvinde            7              26           33       2.01   \n",
       "2         fyr            1               0            1       0.29   \n",
       "3    mandfolk            1               0            1       0.29   \n",
       "4       queer            1               0            1       0.29   \n",
       "5   kvindfolk            1               0            1       0.29   \n",
       "6         tøs            1               0            1       0.29   \n",
       "7         søn            1               1            2       0.29   \n",
       "8      fætter            1               2            3       0.29   \n",
       "9        kone            2               9           11       0.57   \n",
       "10        mor            1               5            6       0.29   \n",
       "11        far            1               5            6       0.29   \n",
       "37      dreng            1               7            8       0.29   \n",
       "38     kusine            0               1            1       0.00   \n",
       "39     søster            0               2            2       0.00   \n",
       "40      herre            0               3            3       0.00   \n",
       "41       pige            1              10           11       0.29   \n",
       "42       bror            1              11           12       0.29   \n",
       "43     datter            0               5            5       0.00   \n",
       "44       dame            0               5            5       0.00   \n",
       "\n",
       "    nontoxic_pct  total_pct  tox_total_diff  tox_total_abs_diff  \n",
       "0           2.50       2.77            1.82                1.82  \n",
       "1           1.14       1.25            0.76                0.76  \n",
       "2           0.00       0.04            0.25                0.25  \n",
       "3           0.00       0.04            0.25                0.25  \n",
       "4           0.00       0.04            0.25                0.25  \n",
       "5           0.00       0.04            0.25                0.25  \n",
       "6           0.00       0.04            0.25                0.25  \n",
       "7           0.04       0.08            0.21                0.21  \n",
       "8           0.09       0.11            0.17                0.17  \n",
       "9           0.39       0.42            0.16                0.16  \n",
       "10          0.22       0.23            0.06                0.06  \n",
       "11          0.22       0.23            0.06                0.06  \n",
       "37          0.31       0.30           -0.02                0.02  \n",
       "38          0.04       0.04           -0.04                0.04  \n",
       "39          0.09       0.08           -0.08                0.08  \n",
       "40          0.13       0.11           -0.11                0.11  \n",
       "41          0.44       0.42           -0.13                0.13  \n",
       "42          0.48       0.46           -0.17                0.17  \n",
       "43          0.22       0.19           -0.19                0.19  \n",
       "44          0.22       0.19           -0.19                0.19  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create df with these occurrence numbers\n",
    "occurrence_df = pd.DataFrame(occur_in_n_texts)\n",
    "\n",
    "# map back to actual lemma and aggregate duplicates\n",
    "occurrence_df[\"lemma\"] = occurrence_df[\"lemmatized_identity\"].map(lemmatized_2_lemma)\n",
    "occurrence_df = occurrence_df.groupby(\"lemma\").agg({\"toxic_count\": \"sum\", \"nontoxic_count\": \"sum\", \"total_count\": \"sum\"}).reset_index()\n",
    "\n",
    "# calculate percentages\n",
    "occurrence_df[\"toxic_pct\"] = (occurrence_df[\"toxic_count\"]/NUM_TOXIC)*100 \n",
    "occurrence_df[\"nontoxic_pct\"] = (occurrence_df[\"nontoxic_count\"]/NUM_NONTOXIC)*100 \n",
    "occurrence_df[\"total_pct\"] = (occurrence_df[\"total_count\"]/NUM_TOTAL)*100 \n",
    "\n",
    "# calculate differences\n",
    "occurrence_df[\"tox_total_diff\"] = occurrence_df[\"toxic_pct\"] - occurrence_df[\"total_pct\"]\n",
    "occurrence_df[\"tox_total_abs_diff\"] = abs(occurrence_df[\"toxic_pct\"] - occurrence_df[\"total_pct\"])\n",
    "\n",
    "# sort by difference\n",
    "sorted_occurrence_df = occurrence_df.sort_values(\"tox_total_diff\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# display rows where toxic pct != total pct\n",
    "sorted_occurrence_df[sorted_occurrence_df[\"tox_total_diff\"] != 0].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this df\n",
    "sorted_occurrence_df.to_excel(os.getcwd()+\"/mitigation/frequency_of_identity_lemmas.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ones with a difference > 0 are the ones that I need to look at. \n",
    "\n",
    "I can actually make a difference here by adding non-toxic data and getting the toxic_pct number closer to the total_pct number, thereby reducing the difference so it's as close to zero as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length differences\n",
    "\n",
    "Percent of comments labeled as toxic at each length containing the given terms, e.g.:\n",
    "\n",
    "| Term | 20-59 | 60-179 |\n",
    "|:---:|:---:|:---:|\n",
    "| ALL | 17% | 12% |\n",
    "| gay | 88% | 77% |\n",
    "| queer | 75% | 83% |\n",
    "| ... | ... | ... |\n",
    "\n",
    "Other lengths:\n",
    "* 180-539\n",
    "* 540-1619\n",
    "* 1620-4859\n",
    "\n",
    "\n",
    "Method:\n",
    "\n",
    "* For each lemma:\n",
    "  * Find the texts that it occur in\n",
    "  * Separate these texts into 5 length buckets\n",
    "  * For each length_bucket:\n",
    "    * Find the percentage that are toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2631/2631 [00:00<00:00, 381155.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# add lengths to df\n",
    "train_orig[\"length\"] = train_orig[\"tweet\"].progress_apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min length: 0\n",
      "Max length: 3518\n"
     ]
    }
   ],
   "source": [
    "# divide into 6 buckets\n",
    "print(\"Min length:\", train_orig[\"length\"].min())\n",
    "print(\"Max length:\", train_orig[\"length\"].max())\n",
    "\n",
    "bin1 = train_orig.query(\"0 <= length <= 19\") # 20\n",
    "bin2 = train_orig.query(\"20 <= length <= 59\") # 40\n",
    "bin3 = train_orig.query(\"60 <= length <= 139\") # 80\n",
    "bin4 = train_orig.query(\"140 <= length <= 299\") # 160\n",
    "bin5 = train_orig.query(\"300 <= length <= 619\") # 320\n",
    "bin6 = train_orig.query(\"620 <= length\") # the rest\n",
    "bins = [bin1, bin2, bin3, bin4, bin5, bin6]\n",
    "bin_labels = [\"0-19\", \"20-59\", \"60-139\", \"140-299\", \"300-619\", \"620-3519\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>bin_range</th>\n",
       "      <th>0-19</th>\n",
       "      <th>20-59</th>\n",
       "      <th>60-139</th>\n",
       "      <th>140-299</th>\n",
       "      <th>300-619</th>\n",
       "      <th>620-3519</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALL</th>\n",
       "      <td>10.74</td>\n",
       "      <td>12.79</td>\n",
       "      <td>13.75</td>\n",
       "      <td>17.5</td>\n",
       "      <td>29.63</td>\n",
       "      <td>33.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "bin_range   0-19  20-59  60-139  140-299  300-619  620-3519\n",
       "ALL        10.74  12.79   13.75     17.5    29.63     33.33"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find proportion of toxic comments for each bin (no specific terms)\n",
    "results = {\"bin_range\":bin_labels, \"toxic\":[], \"nontoxic\":[]}\n",
    "for bin in bins: # length bins\n",
    "    results[\"toxic\"].append(len(bin[bin[\"label\"] == 1])) # count toxic in that bin\n",
    "    results[\"nontoxic\"].append(len(bin[bin[\"label\"] == 0])) # and non-toxic\n",
    "\n",
    "# prepare preliminary results df\n",
    "prel_results_df = pd.DataFrame(results)\n",
    "prel_results_df[\"pct_toxic\"] = ( prel_results_df[\"toxic\"] / (prel_results_df[\"toxic\"]+prel_results_df[\"nontoxic\"]) ) * 100 # add percentage\n",
    "prel_results_df.set_index(\"bin_range\", inplace=True)\n",
    "\n",
    "# add to final results df\n",
    "results_df_1 = prel_results_df[[\"pct_toxic\"]].T\n",
    "results_df_1.index = [\"ALL\"]\n",
    "results_df_1.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for each lemma\n",
    "\n",
    "# prepare dicts\n",
    "toxic_count_dict = {\"lemmatized_identity\": lemmatized_identities}\n",
    "total_count_dict = {\"lemmatized_identity\": lemmatized_identities}\n",
    "for label in bin_labels:\n",
    "    toxic_count_dict[label] = []\n",
    "    total_count_dict[label] = []\n",
    "    \n",
    "for lemma in lemmatized_identities: # for each lemma\n",
    "    for (bin_label, bin) in zip(bin_labels, bins): # for each bin\n",
    "        \n",
    "        # count no. of toxic/all texts this lemma occurs in in this bin\n",
    "        toxic_count = bin[bin[\"label\"]==1][\"lemmas\"].apply(lambda x: occurs_in(target=lemma, text=x)).sum() \n",
    "        total_count = bin[\"lemmas\"].apply(lambda x: occurs_in(target=lemma, text=x)).sum() \n",
    "        \n",
    "        # add to count_dicts\n",
    "        toxic_count_dict[bin_label].append(toxic_count)\n",
    "        total_count_dict[bin_label].append(total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df with these occurrence numbers\n",
    "toxic_count_df = pd.DataFrame(toxic_count_dict)\n",
    "total_count_df = pd.DataFrame(total_count_dict)\n",
    "\n",
    "# map back to actual lemma and aggregate duplicates\n",
    "toxic_count_df[\"lemma\"] = toxic_count_df[\"lemmatized_identity\"].map(lemmatized_2_lemma)\n",
    "toxic_count_df = toxic_count_df.groupby(\"lemma\").agg({\"0-19\": \"sum\", \"20-59\": \"sum\", \"60-139\": \"sum\", \"140-299\": \"sum\", \"300-619\": \"sum\", \"620-3519\": \"sum\"}).reset_index()\n",
    "toxic_count_df[\"sum\"] = toxic_count_df[\"0-19\"] + toxic_count_df[\"20-59\"] + toxic_count_df[\"60-139\"] + toxic_count_df[\"140-299\"] + toxic_count_df[\"300-619\"] + toxic_count_df[\"620-3519\"]\n",
    "toxic_count_df = toxic_count_df.sort_values(\"lemma\")\n",
    "total_count_df[\"lemma\"] = total_count_df[\"lemmatized_identity\"].map(lemmatized_2_lemma)\n",
    "total_count_df = total_count_df.groupby(\"lemma\").agg({\"0-19\": \"sum\", \"20-59\": \"sum\", \"60-139\": \"sum\", \"140-299\": \"sum\", \"300-619\": \"sum\", \"620-3519\": \"sum\"}).reset_index()\n",
    "total_count_df[\"sum\"] = total_count_df[\"0-19\"] + total_count_df[\"20-59\"] + total_count_df[\"60-139\"] + total_count_df[\"140-299\"] + total_count_df[\"300-619\"] + total_count_df[\"620-3519\"]\n",
    "total_count_df = total_count_df.sort_values(\"lemma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0-19', '20-59', '60-139', '140-299', '300-619', '620-3519'], dtype='object')"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_count_df.columns[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to results df\n",
    "results_df_2 = toxic_count_df[[\"lemma\"]]\n",
    "for col in toxic_count_df.columns[1:-1]:\n",
    "    results_df_2[col] = (toxic_count_df[col] / total_count_df[col]) * 100 # calculate percentages\n",
    "results_df_2.set_index(\"lemma\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0-19</th>\n",
       "      <th>20-59</th>\n",
       "      <th>60-139</th>\n",
       "      <th>140-299</th>\n",
       "      <th>300-619</th>\n",
       "      <th>620-3519</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALL</th>\n",
       "      <td>10.74</td>\n",
       "      <td>12.79</td>\n",
       "      <td>13.75</td>\n",
       "      <td>17.5</td>\n",
       "      <td>29.63</td>\n",
       "      <td>33.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bror</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dame</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datter</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dreng</th>\n",
       "      <td></td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fyr</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>100.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fætter</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>herre</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kone</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kusine</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kvinde</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>16.67</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kvindfolk</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>100.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mand</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mandfolk</th>\n",
       "      <td></td>\n",
       "      <td>100.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mor</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>33.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pige</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>queer</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>søn</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>søster</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tøs</th>\n",
       "      <td>100.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0-19  20-59 60-139 140-299 300-619 620-3519\n",
       "ALL        10.74  12.79  13.75    17.5   29.63    33.33\n",
       "bror                0.0    0.0     0.0     0.0     50.0\n",
       "dame                       0.0     0.0                 \n",
       "datter                     0.0     0.0     0.0      0.0\n",
       "dreng             100.0    0.0                      0.0\n",
       "far                 0.0    0.0    50.0              0.0\n",
       "fyr                      100.0                         \n",
       "fætter              0.0          100.0     0.0         \n",
       "herre               0.0    0.0                         \n",
       "kone                0.0    0.0     0.0   100.0     50.0\n",
       "kusine              0.0                                \n",
       "kvinde       0.0   12.5  16.67    40.0     0.0     20.0\n",
       "kvindfolk                                100.0         \n",
       "mand         0.0    8.7   50.0    25.0    25.0    16.67\n",
       "mandfolk          100.0                                \n",
       "mor                      33.33     0.0     0.0      0.0\n",
       "pige                0.0  33.33     0.0     0.0      0.0\n",
       "queer                                             100.0\n",
       "søn                        0.0   100.0                 \n",
       "søster                     0.0     0.0                 \n",
       "tøs        100.0                                       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final df\n",
    "results_df = pd.concat([results_df_1, results_df_2])\n",
    "results_df.dropna(axis = 0, how = 'all', inplace = True) # drop rows with all NA values\n",
    "display(results_df.round(2).fillna(\"\")) # show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "results_df = results_df.fillna(\"\") # fill NAs\n",
    "results_df.to_excel(os.getcwd()+\"/mitigation/toxicity_at_diff_lengths.xlsx\") # save as xlsx file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate how much new data is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from dixon's code\n",
    "# def calculate_non_toxic_deficit(f, n, t):\n",
    "#     \"\"\"\n",
    "#     Calculate the deficit of non-toxic examples needed to achieve the desired non-toxic fraction.\n",
    "\n",
    "#     Parameters:\n",
    "#     - f: Desired non-toxic fraction\n",
    "#     - n: Current number of non-toxic examples\n",
    "#     - t: Current number of toxic examples\n",
    "\n",
    "#     Returns:\n",
    "#     - a: Number of non-toxic examples needed to be added\n",
    "#     \"\"\"\n",
    "#     a = (f * (t + n) - n) / (1 - f)\n",
    "#     return a\n",
    "\n",
    "# # Example usage:\n",
    "# desired_non_toxic_fraction = 2.0\n",
    "# current_non_toxic_examples = 2\n",
    "# current_toxic_examples = 2\n",
    "\n",
    "\n",
    "# deficit_of_non_toxic_examples = calculate_non_toxic_deficit(desired_non_toxic_fraction, current_non_toxic_examples, current_toxic_examples)\n",
    "# deficit_of_non_toxic_examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
