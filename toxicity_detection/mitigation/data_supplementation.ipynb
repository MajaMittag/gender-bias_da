{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Supplementation (suppl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method\n",
    "1.\tIdentify identity terms with the most disproportionate data distributions \n",
    "    1. Stem/lemmatize dataset\n",
    "    2. For each lemma in the synthetic test set:\n",
    "        1. Check distribution across labels in dataset, i.e. difference between frequency in toxic comments and overall\n",
    "        2.\tAlso check length differences!\n",
    "    3. What does this mean exactly? \n",
    "        1.\t“Identity terms affected by the false positive bias are disproportionately used in toxic comments in our training data. For example, the word ‘gay’ appears in 3% of toxic comments but only 0.5% of comments overall.”\n",
    "        2.\tFrequency of identity terms in toxic comments and overall: \n",
    "2.\tAdd additional non-toxic examples that contain the identity terms that appear disproportionately across labels in the original dataset\n",
    "    1.\tUse wiki data – assumed to be non-toxic\n",
    "    2.\tAdd enough so that the balance is in line with the prior distribution for the overall dataset\n",
    "        1.\tE.g. until % “gay” in toxic comment is close to 0.50% as in overall data.\n",
    "3.\tMaybe consider different lengths as CNNs could be sensitive to this\n",
    "    1.\t“toxic comments tend to be shorter” (Dixon et al. 2018)\n",
    "4.\tSupposed to reduce false positives. Could also do the opposite? But more difficult to find toxic comments unless we take them from places that are supposedly toxic (e.g. “roast me”)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\love2\\anaconda3\\envs\\thesis2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# set cwd\n",
    "import os\n",
    "os.chdir(\"g:\\\\My Drive\\\\ITC, 5th semester (Thesis)\\\\Code\\\\Github_code\\\\toxicity_detection\")\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "# from random import choice, choices\n",
    "# from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "# from string import punctuation\n",
    "# # import spacy\n",
    "from spacy import displacy\n",
    "from tqdm import tqdm\n",
    "from utils import load_dkhate\n",
    "# from typing import Dict\n",
    "import pickle\n",
    "import dacy\n",
    "# import utils\n",
    "# import nltk\n",
    "# import re\n",
    "# import string\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text:str) -> str:\n",
    "    \"\"\"Returns a lemmatized version of the text or itself if the string is empty.\"\"\"\n",
    "    if len(text) > 0:\n",
    "        doc = nlp(text)\n",
    "        lemmas = [token.lemma_ for token in doc]\n",
    "        lemmatized_text = \" \".join(lemmas)\n",
    "        return lemmatized_text\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def occurs_in(target, text):\n",
    "    \"\"\"Checks whether a word occurs in a text.\"\"\"\n",
    "    for word in text.split():\n",
    "        if word == target:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DaCy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load daCy model (medium works fine)\n",
    "nlp = dacy.load(\"da_dacy_medium_trf-0.2.0\") # takes around 4 minutes the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token     \tLemma\t\tPOS-tag\t\tEntity type\n",
      "Mit       :\tMit       \tDET\t\t\n",
      "navn      :\tnavn      \tNOUN\t\t\n",
      "er        :\tvære      \tAUX\t\t\n",
      "Maja      :\tMaja      \tPROPN\t\tPER\n",
      ".         :\t.         \tPUNCT\t\t\n",
      "Jeg       :\tjeg       \tPRON\t\t\n",
      "bor       :\tbo        \tVERB\t\t\n",
      "på        :\tpå        \tADP\t\t\n",
      "Bispebjerg:\tBispebjerg\tPROPN\t\tLOC\n",
      ",         :\t,         \tPUNCT\t\t\n",
      "men       :\tmen       \tCCONJ\t\t\n",
      "er        :\tvære      \tVERB\t\t\n",
      "fra       :\tfra       \tADP\t\t\n",
      "Næstved   :\tNæstved   \tPROPN\t\tLOC\n",
      ".         :\t.         \tPUNCT\t\t\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mit navn er \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Maja\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER\n",
       " <a style=\"text-decoration: none; color: inherit; font-weight: normal\" href=\"#\">Q18184581</a>\n",
       "</span>\n",
       "</mark>\n",
       ". Jeg bor på \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bispebjerg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC\n",
       " <a style=\"text-decoration: none; color: inherit; font-weight: normal\" href=\"#\">NIL</a>\n",
       "</span>\n",
       "</mark>\n",
       ", men er fra \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Næstved\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC\n",
       " <a style=\"text-decoration: none; color: inherit; font-weight: normal\" href=\"#\">Q21178</a>\n",
       "</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test that it works as expected \n",
    "doc = nlp(\"Mit navn er Maja. Jeg bor på Bispebjerg, men er fra Næstved.\") \n",
    "print(\"Token     \\tLemma\\t\\tPOS-tag\\t\\tEntity type\")\n",
    "for tok in doc: \n",
    "    print(f\"{str(tok).ljust(10)}:\\t{str(tok.lemma_).ljust(10)}\\t{tok.pos_}\\t\\t{tok.ent_type_}\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>hørt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>reaktion svensker</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>hey champ smide link ser hearthstone henne</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>melder vold voldtægt viser sandt beviser diver...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>betaler omkring mb kb får nok tættere kb kb be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet label\n",
       "id                                                           \n",
       "2378                                               hørt     0\n",
       "1879                                  reaktion svensker     0\n",
       "42           hey champ smide link ser hearthstone henne     0\n",
       "457   melder vold voldtægt viser sandt beviser diver...     1\n",
       "3108  betaler omkring mb kb får nok tættere kb kb be...     0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data splits \n",
    "_, _, y_train_orig, _ = load_dkhate(test_size=0.2)\n",
    "with open(os.getcwd()+\"/data/X_orig_preproc.pkl\", \"rb\") as f:\n",
    "    content = pickle.load(f)\n",
    "\n",
    "X_train_orig = content[\"X_train\"]\n",
    "train_orig = pd.DataFrame([X_train_orig, y_train_orig]).T\n",
    "train_orig.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2631/2631 [06:10<00:00,  7.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# lemmatize the texts\n",
    "train_orig[\"lemmas\"] = train_orig[\"tweet\"].progress_apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1174    scanne lortet pc markere tage underskrift ny d...\n",
       "3301    kunne klarer fyr stort se venn vej samme spor ...\n",
       "1390    fuck meget sol varme lille regn please dansk å...\n",
       "799     hvorfor fucking stor helvede fejre kristn hell...\n",
       "900     ingen udlænding ved grænse heller kriminell ku...\n",
       "Name: lemmas, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into toxic and all text\n",
    "toxic_text = train_orig[train_orig[\"label\"] == 1][\"lemmas\"]\n",
    "all_text = train_orig[\"lemmas\"]\n",
    "\n",
    "NUM_TOXIC = len(toxic_text)\n",
    "NUM_TOTAL = len(all_text)\n",
    "\n",
    "toxic_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load identity terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 unique identity lemmas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity_term</th>\n",
       "      <th>identity_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>transpersonerne</td>\n",
       "      <td>transperson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>transvestitterne</td>\n",
       "      <td>transvestit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>transerne</td>\n",
       "      <td>trans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>androgynerne</td>\n",
       "      <td>androgyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>hermafroditterne</td>\n",
       "      <td>hermafrodit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        identity_term identity_lemma\n",
       "155   transpersonerne    transperson\n",
       "156  transvestitterne    transvestit\n",
       "157         transerne          trans\n",
       "158      androgynerne       androgyn\n",
       "159  hermafroditterne    hermafrodit"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load identity terms\n",
    "identities = pd.read_excel(os.getcwd()+\"/data/identity_terms.xlsx\")\n",
    "print(len(set(identities[\"identity_lemma\"])), \"unique identity lemmas\")\n",
    "identities.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:11<00:00, 14.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 unique lemmatized identity terms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity_term</th>\n",
       "      <th>identity_lemma</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>transpersonerne</td>\n",
       "      <td>transperson</td>\n",
       "      <td>transperson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>transvestitterne</td>\n",
       "      <td>transvestit</td>\n",
       "      <td>transvestitterne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>transerne</td>\n",
       "      <td>trans</td>\n",
       "      <td>transe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>androgynerne</td>\n",
       "      <td>androgyn</td>\n",
       "      <td>androgynerne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>hermafroditterne</td>\n",
       "      <td>hermafrodit</td>\n",
       "      <td>hermafroditterne</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        identity_term identity_lemma        lemmatized\n",
       "155   transpersonerne    transperson       transperson\n",
       "156  transvestitterne    transvestit  transvestitterne\n",
       "157         transerne          trans            transe\n",
       "158      androgynerne       androgyn      androgynerne\n",
       "159  hermafroditterne    hermafrodit  hermafroditterne"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatize the identity terms\n",
    "identities[\"lemmatized\"] = identities[\"identity_term\"].progress_apply(lemmatize_text)\n",
    "print(len(set(identities[\"lemmatized\"])), \"unique lemmatized identity terms\")\n",
    "identities.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map from lemmatized word to the actual lemma\n",
    "lemmatized_2_lemma = dict(zip(identities[\"lemmatized\"], identities[\"identity_lemma\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Data Supplemenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of identity terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should return False. Result: 0\n",
      "This should return True.  Result: 1\n"
     ]
    }
   ],
   "source": [
    "# test function\n",
    "print(\"This should return False. Result:\", occurs_in(\"mor\", \"elsker din humor\"))\n",
    "print(\"This should return True.  Result:\", occurs_in(\"mor\", \"hans mor er pænt sød\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many texts these terms occur in\n",
    "lemmatized_identities = list(set(identities[\"lemmatized\"]))\n",
    "occur_in_n_texts = {\"lemmatized_identity\": lemmatized_identities, \"toxic_count\": [], \"total_count\":[]}\n",
    "\n",
    "for lemma in lemmatized_identities:\n",
    "    occur_in_n_texts[\"toxic_count\"].append(toxic_text.apply(lambda x: occurs_in(target=lemma, text=x)).sum())\n",
    "    occur_in_n_texts[\"total_count\"].append(all_text.apply(lambda x: occurs_in(target=lemma, text=x)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>toxic_count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>toxic_pct</th>\n",
       "      <th>total_pct</th>\n",
       "      <th>difference</th>\n",
       "      <th>abs_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mand</td>\n",
       "      <td>16</td>\n",
       "      <td>73</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kvinde</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fyr</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mandfolk</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kvindfolk</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tøs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>søn</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fætter</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kone</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mor</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>far</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>dreng</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>kusine</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>søster</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>herre</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>pige</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>bror</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>datter</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>dame</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lemma  toxic_count  total_count  toxic_pct  total_pct  difference  \\\n",
       "0        mand           16           73       4.60       2.77        1.82   \n",
       "1      kvinde            7           33       2.01       1.25        0.76   \n",
       "2         fyr            1            1       0.29       0.04        0.25   \n",
       "3    mandfolk            1            1       0.29       0.04        0.25   \n",
       "4       queer            1            1       0.29       0.04        0.25   \n",
       "5   kvindfolk            1            1       0.29       0.04        0.25   \n",
       "6         tøs            1            1       0.29       0.04        0.25   \n",
       "7         søn            1            2       0.29       0.08        0.21   \n",
       "8      fætter            1            3       0.29       0.11        0.17   \n",
       "9        kone            2           11       0.57       0.42        0.16   \n",
       "10        mor            1            6       0.29       0.23        0.06   \n",
       "11        far            1            6       0.29       0.23        0.06   \n",
       "37      dreng            1            8       0.29       0.30       -0.02   \n",
       "38     kusine            0            1       0.00       0.04       -0.04   \n",
       "39     søster            0            2       0.00       0.08       -0.08   \n",
       "40      herre            0            3       0.00       0.11       -0.11   \n",
       "41       pige            1           11       0.29       0.42       -0.13   \n",
       "42       bror            1           12       0.29       0.46       -0.17   \n",
       "43     datter            0            5       0.00       0.19       -0.19   \n",
       "44       dame            0            5       0.00       0.19       -0.19   \n",
       "\n",
       "    abs_difference  \n",
       "0             1.82  \n",
       "1             0.76  \n",
       "2             0.25  \n",
       "3             0.25  \n",
       "4             0.25  \n",
       "5             0.25  \n",
       "6             0.25  \n",
       "7             0.21  \n",
       "8             0.17  \n",
       "9             0.16  \n",
       "10            0.06  \n",
       "11            0.06  \n",
       "37            0.02  \n",
       "38            0.04  \n",
       "39            0.08  \n",
       "40            0.11  \n",
       "41            0.13  \n",
       "42            0.17  \n",
       "43            0.19  \n",
       "44            0.19  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create df with these occurrence numbers\n",
    "occurrence_df = pd.DataFrame(occur_in_n_texts)\n",
    "\n",
    "# map back to actual lemma and aggregate duplicates\n",
    "occurrence_df[\"lemma\"] = occurrence_df[\"lemmatized_identity\"].map(lemmatized_2_lemma)\n",
    "occurrence_df = occurrence_df.groupby(\"lemma\").agg({\"toxic_count\": \"sum\", \"total_count\": \"sum\"}).reset_index()\n",
    "\n",
    "# calculate percentages\n",
    "occurrence_df[\"toxic_pct\"] = (occurrence_df[\"toxic_count\"]/NUM_TOXIC)*100 \n",
    "occurrence_df[\"total_pct\"] = (occurrence_df[\"total_count\"]/NUM_TOTAL)*100 \n",
    "\n",
    "# calculate differences\n",
    "occurrence_df[\"difference\"] = occurrence_df[\"toxic_pct\"] - occurrence_df[\"total_pct\"]\n",
    "occurrence_df[\"abs_difference\"] = abs(occurrence_df[\"toxic_pct\"] - occurrence_df[\"total_pct\"])\n",
    "\n",
    "# sort by difference\n",
    "sorted_occurrence_df = occurrence_df.sort_values(\"difference\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# display rows where toxic pct != total pct\n",
    "sorted_occurrence_df[sorted_occurrence_df[\"difference\"] != 0].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this df\n",
    "sorted_occurrence_df.to_excel(os.getcwd()+\"/mitigation/frequency_of_identity_lemmas.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ones with a difference > 0 are the ones that I need to look at. \n",
    "\n",
    "I can actually make a difference here by adding non-toxic data and getting the toxic_pct number closer to the total_pct number, thereby reducing the difference so it's as close to zero as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length differences\n",
    "\n",
    "Percent of comments labeled as toxic at each length containing the given terms, e.g.:\n",
    "\n",
    "| Term | 20-59 | 60-179 |\n",
    "|:---:|:---:|:---:|\n",
    "| ALL | 17% | 12% |\n",
    "| gay | 88% | 77% |\n",
    "| queer | 75% | 83% |\n",
    "| ... | ... | ... |\n",
    "\n",
    "Other lengths:\n",
    "* 180-539\n",
    "* 540-1619\n",
    "* 1620-4859\n",
    "\n",
    "\n",
    "Method:\n",
    "\n",
    "* For each lemma:\n",
    "  * Find the texts that it occur in\n",
    "  * Separate these texts into 5 length buckets\n",
    "  * For each length_bucket:\n",
    "    * Find the percentage that are toxic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
