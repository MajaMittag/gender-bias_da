{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loading and using models – benchmark models as well\n",
    "\n",
    "### It works for all models now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\love2\\anaconda3\\envs\\thesis2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from danlp.models import load_bert_tone_model # BERT Tone\n",
    "from danlp.datasets import EuroparlSentiment1, LccSentiment\n",
    "import operator # for the SpaCy model\n",
    "from sklearn.metrics import classification_report\n",
    "import spacy # SpaCy model\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline # for the XLM Roberta model and the SENDA model\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpaCy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DOES NOT WORK !!!\n",
    "\n",
    "# # load the model\n",
    "# from danlp.models import load_spacy_model # SpaCy model (doesn't work)\n",
    "# nlp = load_spacy_model(textcat='sentiment') # if you got an error saying da.vectors not found, try setting vectorError=True - it is an temp fix\n",
    "\n",
    "# # I cannot figure out how to fix this error\n",
    "# # it has been an open issue for over a year, see: https://github.com/alexandrainst/danlp/issues/169\n",
    "# # generally, it seems like DaNLP aren't updated very regularly, if at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I couldn't get it to work using danlp, so instead, I used the version on huggingface, which I hope is the same, but I'm not 100% sure**\n",
    "\n",
    "Installation guide from huggingface (https://huggingface.co/mirfan899/da_spacy_sentiment):\n",
    "\n",
    "```\n",
    "!pip install https://huggingface.co/mirfan899/da_spacy_sentiment/resolve/main/da_spacy_sentiment-any-py3-none-any.whl\n",
    "\n",
    "# Using spacy.load().\n",
    "import spacy\n",
    "nlp = spacy.load(\"da_spacy_sentiment\")\n",
    "\n",
    "# Importing as module.\n",
    "import da_spacy_sentiment\n",
    "nlp = da_spacy_sentiment.load()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "spacy_clf = spacy.load(\"da_spacy_sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence     : \"Denne dame er soldat.\"\n",
      "Prediction   : neutral\n",
      "  •  Positive:  1.52 %\n",
      "  •  Neutral : 94.09 %\n",
      "  •  Negative:  4.38 %\n",
      "--------------------------------------------------\n",
      "Sentence     : \"Denne herre er soldat.\"\n",
      "Prediction   : neutral\n",
      "  •  Positive:  3.61 %\n",
      "  •  Neutral : 93.38 %\n",
      "  •  Negative:   3.0 %\n",
      "--------------------------------------------------\n",
      "Sentence     : \"Dette interkønnede individ er soldat.\"\n",
      "Prediction   : negative\n",
      "  •  Positive:  13.5 %\n",
      "  •  Neutral :  23.1 %\n",
      "  •  Negative:  63.4 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# test that it works\n",
    "# doc.cats is the dict of predicted probas (keys = \"neutral\", \"negative\", and \"positive\")\n",
    "\n",
    "test_sentences = [\"Denne dame er soldat.\", \"Denne herre er soldat.\", \"Dette interkønnede individ er soldat.\"]\n",
    "\n",
    "for s in test_sentences:\n",
    "    probas = spacy_clf(s).cats\n",
    "    pos, neu, neg = probas[\"positive\"], probas[\"neutral\"], probas[\"negative\"]\n",
    "    print(f'Sentence     : \"{s}\"')\n",
    "    print(\"Prediction   :\", max(probas.items(), key=operator.itemgetter(1))[0])\n",
    "    print(\"  •  Positive:\", str(round(pos*100,2)).rjust(5), \"%\")\n",
    "    print(\"  •  Neutral :\", str(round(neu*100,2)).rjust(5), \"%\")\n",
    "    print(\"  •  Negative:\", str(round(neg*100,2)).rjust(5), \"%\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "bert_clf = load_bert_tone_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence     : \"Denne dame er soldat.\"\n",
      "Analytic     : objective\n",
      "Prediction   : neutral\n",
      "  •  Positive:  3.66 %\n",
      "  •  Neutral : 85.49 %\n",
      "  •  Negative: 10.85 %\n",
      "--------------------------------------------------\n",
      "Sentence     : \"Denne herre er soldat.\"\n",
      "Analytic     : objective\n",
      "Prediction   : neutral\n",
      "  •  Positive:  0.21 %\n",
      "  •  Neutral : 99.01 %\n",
      "  •  Negative:  0.78 %\n",
      "--------------------------------------------------\n",
      "Sentence     : \"Dette interkønnede individ er soldat.\"\n",
      "Analytic     : subjective\n",
      "Prediction   : negative\n",
      "  •  Positive:  7.61 %\n",
      "  •  Neutral :  3.97 %\n",
      "  •  Negative: 88.42 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# test that it works\n",
    "\n",
    "test_sentences = [\"Denne dame er soldat.\", \"Denne herre er soldat.\", \"Dette interkønnede individ er soldat.\"]\n",
    "\n",
    "for s in test_sentences:\n",
    "    pos, neu, neg = bert_clf.predict_proba(s)[0]\n",
    "    print(f'Sentence     : \"{s}\"')\n",
    "    print(\"Analytic     :\", bert_clf.predict(s)[\"analytic\"])\n",
    "    print(\"Prediction   :\", bert_clf.predict(s)[\"polarity\"])\n",
    "    print(\"  •  Positive:\", str(round(pos*100,2)).rjust(5), \"%\")\n",
    "    print(\"  •  Neutral :\", str(round(neu*100,2)).rjust(5), \"%\")\n",
    "    print(\"  •  Negative:\", str(round(neg*100,2)).rjust(5), \"%\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLM Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': 0.9918450713157654,\n",
       " 'neutral': 0.0065132384188473225,\n",
       " 'negative': 0.0016416909638792276}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_label_score_dict(top_k_list:List[Dict[str,str]]) -> dict:\n",
    "    \"\"\"Convert a list of top-k probabilities (each being a dict of label and score) into a dictionary of the format {label: score}.\n",
    "\n",
    "    Args:\n",
    "        top_k_list (List[Dict[str,str]]): a list of dictionaries that contain the top-k probabilities.\n",
    "\n",
    "    Returns:\n",
    "        dict: a dictionary containing the top-k probabilities arranged by label and score.\n",
    "    \"\"\"\n",
    "    new_dict = {}\n",
    "    for proba_dict in top_k_list:\n",
    "        new_dict[proba_dict[\"label\"].lower()] = proba_dict[\"score\"]\n",
    "    return new_dict\n",
    "\n",
    "# example (scores are from the sentences \"this is a loverly message\")\n",
    "topk = [{'label': 'Positive', 'score': 0.9918450713157654},\n",
    "        {'label': 'Neutral', 'score': 0.0065132384188473225},\n",
    "        {'label': 'Negative', 'score': 0.0016416909638792276}]\n",
    "label_score_d = convert_to_label_score_dict(topk)\n",
    "label_score_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.1.2+cu121 with CUDA 1201 (you have 2.1.2+cpu)\n",
      "    Python  3.9.13 (you have 3.9.18)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model_path = \"citizenlab/twitter-xlm-roberta-base-sentiment-finetunned\"\n",
    "roberta_clf = pipeline(\"text-classification\", model=model_path, tokenizer=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence     : \"Denne dame er soldat.\"\n",
      "Prediction   : neutral\n",
      "  •  Positive:  1.31 %\n",
      "  •  Neutral : 96.61 %\n",
      "  •  Negative:  2.08 %\n",
      "--------------------------------------------------\n",
      "Sentence     : \"Denne herre er soldat.\"\n",
      "Prediction   : neutral\n",
      "  •  Positive: 10.82 %\n",
      "  •  Neutral : 84.21 %\n",
      "  •  Negative:  4.97 %\n",
      "--------------------------------------------------\n",
      "Sentence     : \"Dette interkønnede individ er soldat.\"\n",
      "Prediction   : neutral\n",
      "  •  Positive:  0.84 %\n",
      "  •  Neutral : 97.57 %\n",
      "  •  Negative:  1.59 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\"Denne dame er soldat.\", \"Denne herre er soldat.\", \"Dette interkønnede individ er soldat.\"]\n",
    "\n",
    "for s in test_sentences:\n",
    "    probas_list = roberta_clf(s, top_k=None)\n",
    "    probas = convert_to_label_score_dict(probas_list)\n",
    "    pos, neu, neg = probas[\"positive\"], probas[\"neutral\"], probas[\"negative\"]\n",
    "    print(f'Sentence     : \"{s}\"')\n",
    "    print(\"Prediction   :\", max(probas.items(), key=operator.itemgetter(1))[0])\n",
    "    print(\"  •  Positive:\", str(round(pos*100,2)).rjust(5), \"%\")\n",
    "    print(\"  •  Neutral :\", str(round(neu*100,2)).rjust(5), \"%\")\n",
    "    print(\"  •  Negative:\", str(round(neg*100,2)).rjust(5), \"%\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SENDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "senda_tokenizer = AutoTokenizer.from_pretrained(\"pin/senda\")\n",
    "senda_clf = AutoModelForSequenceClassification.from_pretrained(\"pin/senda\")\n",
    "senda_pipeline = pipeline(\"sentiment-analysis\", model=senda_clf, tokenizer=senda_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence     : \"Denne dame er soldat.\"\n",
      "Prediction   : neutral\n",
      "  •  Positive:  20.5 %\n",
      "  •  Neutral : 53.68 %\n",
      "  •  Negative: 25.83 %\n",
      "--------------------------------------------------\n",
      "Sentence     : \"Denne herre er soldat.\"\n",
      "Prediction   : neutral\n",
      "  •  Positive: 18.73 %\n",
      "  •  Neutral : 62.39 %\n",
      "  •  Negative: 18.88 %\n",
      "--------------------------------------------------\n",
      "Sentence     : \"Dette interkønnede individ er soldat.\"\n",
      "Prediction   : neutral\n",
      "  •  Positive: 11.42 %\n",
      "  •  Neutral : 49.41 %\n",
      "  •  Negative: 39.17 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\"Denne dame er soldat.\", \"Denne herre er soldat.\", \"Dette interkønnede individ er soldat.\"]\n",
    "\n",
    "for s in test_sentences:\n",
    "    probas_list = senda_pipeline(s, top_k=None)\n",
    "    probas = convert_to_label_score_dict(probas_list)\n",
    "    pos, neu, neg = probas[\"positiv\"], probas[\"neutral\"], probas[\"negativ\"]\n",
    "    print(f'Sentence     : \"{s}\"')\n",
    "    print(\"Prediction   :\", max(probas.items(), key=operator.itemgetter(1))[0])\n",
    "    print(\"  •  Positive:\", str(round(pos*100,2)).rjust(5), \"%\")\n",
    "    print(\"  •  Neutral :\", str(round(neu*100,2)).rjust(5), \"%\")\n",
    "    print(\"  •  Negative:\", str(round(neg*100,2)).rjust(5), \"%\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark models\n",
    "Inspired by the benchmark script from https://github.com/alexandrainst/danlp/blob/master/examples/benchmarks/sentiment_benchmark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function\n",
    "def score_to_label(score):\n",
    "    \"\"\"\n",
    "    Maps from a sentiment score to a sentiment label. Positive values = 'positive', negative values = 'negative', zero = 'neutral'.\n",
    "    \"\"\"\n",
    "    if score == 0:\n",
    "        return \"neutral\"\n",
    "    elif score > 0:\n",
    "        return \"positive\"\n",
    "    elif score < 0:\n",
    "        return \"negative\"\n",
    "    else: \n",
    "        raise Exception(f\"Score is not accounted for by code: {score}\")\n",
    "\n",
    "def DA_to_EN(label):\n",
    "    \"\"\"\n",
    "    Maps from a (ternary) Danish sentiment label to the English equivalent.\n",
    "    positiv -> positive\n",
    "    negativ -> negative\n",
    "    neutral -> neutral (unchanged)\n",
    "    \"\"\"\n",
    "    if label == \"positiv\":\n",
    "        return \"positive\"\n",
    "    elif label == \"negativ\":\n",
    "        return \"negative\"\n",
    "    elif label == \"neutral\":\n",
    "        return label\n",
    "    else:\n",
    "        raise Exception(f\"Label is not accounted for by code: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Danish sentiment classification datasets: https://huggingface.co/datasets?task_ids=task_ids:sentiment-classification&language=language:da&sort=trending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Genoptagelse af sessionen Jeg erklærer Europa-...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Endnu en gang vil jeg ønske Dem godt nytår , o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Som De kan se , indfandt det store \" år 2000-p...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>Til gengæld har borgerne i en del af medlemsla...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>De har udtrykt ønske om en debat om dette emne...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   valence                                               text     label\n",
       "0      0.0  Genoptagelse af sessionen Jeg erklærer Europa-...   neutral\n",
       "1      2.0  Endnu en gang vil jeg ønske Dem godt nytår , o...  positive\n",
       "2      1.0  Som De kan se , indfandt det store \" år 2000-p...  positive\n",
       "3     -3.0  Til gengæld har borgerne i en del af medlemsla...  negative\n",
       "4      0.0  De har udtrykt ønske om en debat om dette emne...   neutral"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\love2\\anaconda3\\envs\\thesis2\\lib\\site-packages\\danlp\\datasets\\sentiment.py:93: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df1.append(df2, sort=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>09:05 DR2 Morgen - med Camilla Thorning og Mor...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>09-10 sæson Spa Francorchamps S2000 Vinter Cup...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>½ time og pensl dem derefter med et sammenpisk...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10-06-2010 Forslag til sportsudvalg. 06-06-201...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100% økologisk rå naturlig bomuld, som efterfø...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   valence                                               text     label\n",
       "0      0.0  09:05 DR2 Morgen - med Camilla Thorning og Mor...   neutral\n",
       "1      2.0  09-10 sæson Spa Francorchamps S2000 Vinter Cup...  positive\n",
       "2      0.0  ½ time og pensl dem derefter med et sammenpisk...   neutral\n",
       "3      0.0  10-06-2010 Forslag til sportsudvalg. 06-06-201...   neutral\n",
       "4      0.0  100% økologisk rå naturlig bomuld, som efterfø...   neutral"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load datasets and map to labels (ternary)\n",
    "\n",
    "# Europarl Sentiment 1\n",
    "eurosent = EuroparlSentiment1()\n",
    "eu_benchdata = eurosent.load_with_pandas()\n",
    "eu_benchdata[\"label\"] = eu_benchdata[\"valence\"].apply(score_to_label)\n",
    "display(eu_benchdata.head())\n",
    "\n",
    "# LCC Sentiment\n",
    "lccsent = LccSentiment()\n",
    "lcc_benchdata = lccsent.load_with_pandas()\n",
    "lcc_benchdata[\"label\"] = lcc_benchdata[\"valence\"].apply(score_to_label)\n",
    "display(lcc_benchdata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark function\n",
    "def benchmark(df, model, modelname, dataname) -> None:\n",
    "    \"\"\"\n",
    "    Benchmark model on a dataset. Prints the sentences per second as well as the classification report.\n",
    "    \"\"\"\n",
    "    print(f\"Model = {modelname}, data = {dataname}\")\n",
    "    start = time.time() # keep track of time\n",
    "    \n",
    "    # make predictions\n",
    "    if modelname.lower() == \"senda\" or modelname.lower() == \"xlm roberta\":\n",
    "        df[\"pred\"] = df.text.map(lambda x: model(x, top_k=1)[0][\"label\"].lower()) # top-1 predicted class label\n",
    "    elif modelname.lower() == \"bert tone\":\n",
    "        df[\"pred\"] = df.text.map(lambda x: model.predict(x, analytic=False)[\"polarity\"].lower())\n",
    "    elif modelname.lower() == \"spacy\":\n",
    "        df[\"pred\"] = df.text.map(lambda x: max(spacy_clf(x).cats.items(), key=operator.itemgetter(1))[0])\n",
    "    else:\n",
    "        raise Exception(\"Model not supported\")\n",
    "    \n",
    "    # print sentences per second\n",
    "    sent_per_sec = len(df) // (time.time() - start)\n",
    "    print(f\"~ {sent_per_sec} sentences per second\")\n",
    "    \n",
    "    # map SENDA predictions to English labels \n",
    "    if modelname.lower() == \"senda\":\n",
    "        df[\"pred\"] = df[\"pred\"].map(lambda x: DA_to_EN(x))\n",
    "    \n",
    "    # print classification report\n",
    "    print(classification_report(df[\"label\"], df[\"pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model = SpaCy, data = Europarl1\n",
      "~ 94.0 sentences per second\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.36      0.19      0.25        53\n",
      "     neutral       0.43      0.66      0.52        80\n",
      "    positive       0.35      0.24      0.28        51\n",
      "\n",
      "    accuracy                           0.41       184\n",
      "   macro avg       0.38      0.36      0.35       184\n",
      "weighted avg       0.39      0.41      0.38       184\n",
      "\n",
      "\n",
      "Model = SpaCy, data = LCC\n",
      "~ 87.0 sentences per second\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.27      0.14      0.18        94\n",
      "     neutral       0.58      0.75      0.65       276\n",
      "    positive       0.35      0.26      0.30       129\n",
      "\n",
      "    accuracy                           0.51       499\n",
      "   macro avg       0.40      0.38      0.38       499\n",
      "weighted avg       0.46      0.51      0.47       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SpaCy\n",
    "benchmark(df=eu_benchdata, model=spacy_clf, modelname=\"SpaCy\", dataname=\"Europarl1\")\n",
    "print()\n",
    "benchmark(df=lcc_benchdata, model=spacy_clf, modelname=\"SpaCy\", dataname=\"LCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model = BERT Tone, data = Europarl1\n",
      "~ 14.0 sentences per second\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.58      0.71        53\n",
      "     neutral       0.72      0.91      0.81        80\n",
      "    positive       0.84      0.80      0.82        51\n",
      "\n",
      "    accuracy                           0.79       184\n",
      "   macro avg       0.82      0.77      0.78       184\n",
      "weighted avg       0.81      0.79      0.78       184\n",
      "\n",
      "\n",
      "Model = BERT Tone, data = LCC\n",
      "~ 12.0 sentences per second\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.40      0.50        94\n",
      "     neutral       0.73      0.89      0.80       276\n",
      "    positive       0.81      0.64      0.72       129\n",
      "\n",
      "    accuracy                           0.74       499\n",
      "   macro avg       0.73      0.65      0.67       499\n",
      "weighted avg       0.74      0.74      0.72       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BERT Tone\n",
    "benchmark(df=eu_benchdata, model=bert_clf, modelname=\"BERT Tone\", dataname=\"Europarl1\")\n",
    "print()\n",
    "benchmark(df=lcc_benchdata, model=bert_clf, modelname=\"BERT Tone\", dataname=\"LCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model = XLM Roberta, data = Europarl1\n",
      "~ 13.0 sentences per second\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.30      0.46        53\n",
      "     neutral       0.53      1.00      0.69        80\n",
      "    positive       1.00      0.31      0.48        51\n",
      "\n",
      "    accuracy                           0.61       184\n",
      "   macro avg       0.82      0.54      0.54       184\n",
      "weighted avg       0.78      0.61      0.57       184\n",
      "\n",
      "\n",
      "Model = XLM Roberta, data = LCC\n",
      "~ 12.0 sentences per second\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.12      0.21        94\n",
      "     neutral       0.59      0.99      0.74       276\n",
      "    positive       1.00      0.16      0.28       129\n",
      "\n",
      "    accuracy                           0.61       499\n",
      "   macro avg       0.81      0.42      0.41       499\n",
      "weighted avg       0.74      0.61      0.52       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XLM Roberta\n",
    "benchmark(df=eu_benchdata, model=roberta_clf, modelname=\"XLM Roberta\", dataname=\"Europarl1\")\n",
    "print()\n",
    "benchmark(df=lcc_benchdata, model=roberta_clf, modelname=\"XLM Roberta\", dataname=\"LCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model = SENDA, data = Europarl1\n",
      "~ 15.0 sentences per second\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.60      0.73        53\n",
      "     neutral       0.66      0.93      0.77        80\n",
      "    positive       0.86      0.63      0.73        51\n",
      "\n",
      "    accuracy                           0.75       184\n",
      "   macro avg       0.81      0.72      0.74       184\n",
      "weighted avg       0.79      0.75      0.75       184\n",
      "\n",
      "\n",
      "Model = SENDA, data = LCC\n",
      "~ 13.0 sentences per second\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.31      0.41        94\n",
      "     neutral       0.66      0.89      0.76       276\n",
      "    positive       0.82      0.50      0.63       129\n",
      "\n",
      "    accuracy                           0.68       499\n",
      "   macro avg       0.69      0.57      0.60       499\n",
      "weighted avg       0.69      0.68      0.66       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SENDA\n",
    "benchmark(df=eu_benchdata, model=senda_pipeline, modelname=\"SENDA\", dataname=\"Europarl1\")\n",
    "print()\n",
    "benchmark(df=lcc_benchdata, model=senda_pipeline, modelname=\"SENDA\", dataname=\"LCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>09:05 DR2 Morgen - med Camilla Thorning og Mor...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>09-10 sæson Spa Francorchamps S2000 Vinter Cup...</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>½ time og pensl dem derefter med et sammenpisk...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10-06-2010 Forslag til sportsudvalg. 06-06-201...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100% økologisk rå naturlig bomuld, som efterfø...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>Publiceret: 23. Marts 2010 06:00 Kvinde kørte ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>»Jeg advarede amerikanerne og den irakiske reg...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>Jim Paul forudser, at Storbritannien vil tilsl...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>Jack Straw begrunder kravet med at det i modsa...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>Men mod halvlegens slutning fik værterne probl...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     valence                                               text     label  \\\n",
       "0        0.0  09:05 DR2 Morgen - med Camilla Thorning og Mor...   neutral   \n",
       "1        2.0  09-10 sæson Spa Francorchamps S2000 Vinter Cup...  positive   \n",
       "2        0.0  ½ time og pensl dem derefter med et sammenpisk...   neutral   \n",
       "3        0.0  10-06-2010 Forslag til sportsudvalg. 06-06-201...   neutral   \n",
       "4        0.0  100% økologisk rå naturlig bomuld, som efterfø...   neutral   \n",
       "..       ...                                                ...       ...   \n",
       "105     -2.0  Publiceret: 23. Marts 2010 06:00 Kvinde kørte ...  negative   \n",
       "107     -2.0  »Jeg advarede amerikanerne og den irakiske reg...  negative   \n",
       "108     -2.0  Jim Paul forudser, at Storbritannien vil tilsl...  negative   \n",
       "110     -2.0  Jack Straw begrunder kravet med at det i modsa...  negative   \n",
       "111     -2.0  Men mod halvlegens slutning fik værterne probl...  negative   \n",
       "\n",
       "         pred  \n",
       "0     neutral  \n",
       "1     neutral  \n",
       "2     neutral  \n",
       "3     neutral  \n",
       "4     neutral  \n",
       "..        ...  \n",
       "105   neutral  \n",
       "107  negative  \n",
       "108   neutral  \n",
       "110  negative  \n",
       "111   neutral  \n",
       "\n",
       "[499 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcc_benchdata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
