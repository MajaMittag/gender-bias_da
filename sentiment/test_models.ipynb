{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loading and using models\n",
    "\n",
    "### It works for all models now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from danlp.models import load_bert_tone_model # BERT Tone\n",
    "import operator # for the SpaCy model\n",
    "import spacy # SpaCy model\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline # for the XLM Roberta model and the SENDA model\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpaCy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DOES NOT WORK !!!\n",
    "\n",
    "# # load the model\n",
    "# from danlp.models import load_spacy_model # SpaCy model (doesn't work)\n",
    "# nlp = load_spacy_model(textcat='sentiment') # if you got an error saying da.vectors not found, try setting vectorError=True - it is an temp fix\n",
    "\n",
    "# # I cannot figure out how to fix this error\n",
    "# # it has been an open issue for over a year, see: https://github.com/alexandrainst/danlp/issues/169\n",
    "# # generally, it seems like DaNLP aren't updated very regularly, if at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I couldn't get it to work using danlp, so instead, I used the version on huggingface, which I hope is the same, but I'm not 100% sure**\n",
    "\n",
    "Installation guide from huggingface (https://huggingface.co/mirfan899/da_spacy_sentiment):\n",
    "\n",
    "```\n",
    "!pip install https://huggingface.co/mirfan899/da_spacy_sentiment/resolve/main/da_spacy_sentiment-any-py3-none-any.whl\n",
    "\n",
    "# Using spacy.load().\n",
    "import spacy\n",
    "nlp = spacy.load(\"da_spacy_sentiment\")\n",
    "\n",
    "# Importing as module.\n",
    "import da_spacy_sentiment\n",
    "nlp = da_spacy_sentiment.load()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "spacy_clf = spacy.load(\"da_spacy_sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence     : \"Denne dame er soldat.\"\n",
      "Prediction   : neutral\n",
      "  •  Positive:  1.52 %\n",
      "  •  Neutral : 94.09 %\n",
      "  •  Negative:  4.38 %\n",
      "--------------------------------------------------\n",
      "Sentence     : \"Denne herre er soldat.\"\n",
      "Prediction   : neutral\n",
      "  •  Positive:  3.61 %\n",
      "  •  Neutral : 93.38 %\n",
      "  •  Negative:   3.0 %\n",
      "--------------------------------------------------\n",
      "Sentence     : \"Dette interkønnede individ er soldat.\"\n",
      "Prediction   : negative\n",
      "  •  Positive:  13.5 %\n",
      "  •  Neutral :  23.1 %\n",
      "  •  Negative:  63.4 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# test that it works\n",
    "# doc.cats is the dict of predicted probas (keys = \"neutral\", \"negative\", and \"positive\")\n",
    "\n",
    "test_sentences = [\"Denne dame er soldat.\", \"Denne herre er soldat.\", \"Dette interkønnede individ er soldat.\"]\n",
    "\n",
    "for s in test_sentences:\n",
    "    probas = spacy_clf(s).cats\n",
    "    pos, neu, neg = probas[\"positive\"], probas[\"neutral\"], probas[\"negative\"]\n",
    "    print(f'Sentence     : \"{s}\"')\n",
    "    print(\"Prediction   :\", max(probas.items(), key=operator.itemgetter(1))[0])\n",
    "    print(\"  •  Positive:\", str(round(pos*100,2)).rjust(5), \"%\")\n",
    "    print(\"  •  Neutral :\", str(round(neu*100,2)).rjust(5), \"%\")\n",
    "    print(\"  •  Negative:\", str(round(neg*100,2)).rjust(5), \"%\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'LABEL_0', '1': 'LABEL_1'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "bert_clf = load_bert_tone_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence     : \"Denne dame er soldat.\"\n",
      "Analytic     : objective\n",
      "Prediction   : neutral\n",
      "  •  Positive:  3.66 %\n",
      "  •  Neutral : 85.49 %\n",
      "  •  Negative: 10.85 %\n",
      "--------------------------------------------------\n",
      "Sentence     : \"Denne herre er soldat.\"\n",
      "Analytic     : objective\n",
      "Prediction   : neutral\n",
      "  •  Positive:  0.21 %\n",
      "  •  Neutral : 99.01 %\n",
      "  •  Negative:  0.78 %\n",
      "--------------------------------------------------\n",
      "Sentence     : \"Dette interkønnede individ er soldat.\"\n",
      "Analytic     : subjective\n",
      "Prediction   : negative\n",
      "  •  Positive:  7.61 %\n",
      "  •  Neutral :  3.97 %\n",
      "  •  Negative: 88.42 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# test that it works\n",
    "\n",
    "test_sentences = [\"Denne dame er soldat.\", \"Denne herre er soldat.\", \"Dette interkønnede individ er soldat.\"]\n",
    "\n",
    "for s in test_sentences:\n",
    "    pos, neu, neg = bert_clf.predict_proba(s)[0]\n",
    "    print(f'Sentence     : \"{s}\"')\n",
    "    print(\"Analytic     :\", bert_clf.predict(s)[\"analytic\"])\n",
    "    print(\"Prediction   :\", bert_clf.predict(s)[\"polarity\"])\n",
    "    print(\"  •  Positive:\", str(round(pos*100,2)).rjust(5), \"%\")\n",
    "    print(\"  •  Neutral :\", str(round(neu*100,2)).rjust(5), \"%\")\n",
    "    print(\"  •  Negative:\", str(round(neg*100,2)).rjust(5), \"%\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLM Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': 0.9918450713157654,\n",
       " 'neutral': 0.0065132384188473225,\n",
       " 'negative': 0.0016416909638792276}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_label_score_dict(top_k_list:List[Dict[str,str]]) -> dict:\n",
    "    \"\"\"Convert a list of top-k probabilities (each being a dict of label and score) into a dictionary of the format {label: score}.\n",
    "\n",
    "    Args:\n",
    "        top_k_list (List[Dict[str,str]]): a list of dictionaries that contain the top-k probabilities.\n",
    "\n",
    "    Returns:\n",
    "        dict: a dictionary containing the top-k probabilities arranged by label and score.\n",
    "    \"\"\"\n",
    "    new_dict = {}\n",
    "    for proba_dict in top_k_list:\n",
    "        new_dict[proba_dict[\"label\"].lower()] = proba_dict[\"score\"]\n",
    "    return new_dict\n",
    "\n",
    "# example (scores are from the sentences \"this is a loverly message\")\n",
    "topk = [{'label': 'Positive', 'score': 0.9918450713157654},\n",
    "        {'label': 'Neutral', 'score': 0.0065132384188473225},\n",
    "        {'label': 'Negative', 'score': 0.0016416909638792276}]\n",
    "label_score_d = convert_to_label_score_dict(topk)\n",
    "label_score_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.1.2+cu121 with CUDA 1201 (you have 2.1.2+cpu)\n",
      "    Python  3.9.13 (you have 3.9.18)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model_path = \"citizenlab/twitter-xlm-roberta-base-sentiment-finetunned\"\n",
    "roberta_clf = pipeline(\"text-classification\", model=model_path, tokenizer=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence     : \"Denne dame er soldat.\"\n",
      "Prediction   : neutral\n",
      "  •  Positive:  1.31 %\n",
      "  •  Neutral : 96.61 %\n",
      "  •  Negative:  2.08 %\n",
      "--------------------------------------------------\n",
      "Sentence     : \"Denne herre er soldat.\"\n",
      "Prediction   : neutral\n",
      "  •  Positive: 10.82 %\n",
      "  •  Neutral : 84.21 %\n",
      "  •  Negative:  4.97 %\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence     : \"Dette interkønnede individ er soldat.\"\n",
      "Prediction   : neutral\n",
      "  •  Positive:  0.84 %\n",
      "  •  Neutral : 97.57 %\n",
      "  •  Negative:  1.59 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\"Denne dame er soldat.\", \"Denne herre er soldat.\", \"Dette interkønnede individ er soldat.\"]\n",
    "\n",
    "for s in test_sentences:\n",
    "    probas_list = roberta_clf(s, top_k=None)\n",
    "    probas = convert_to_label_score_dict(probas_list)\n",
    "    pos, neu, neg = probas[\"positive\"], probas[\"neutral\"], probas[\"negative\"]\n",
    "    print(f'Sentence     : \"{s}\"')\n",
    "    print(\"Prediction   :\", max(probas.items(), key=operator.itemgetter(1))[0])\n",
    "    print(\"  •  Positive:\", str(round(pos*100,2)).rjust(5), \"%\")\n",
    "    print(\"  •  Neutral :\", str(round(neu*100,2)).rjust(5), \"%\")\n",
    "    print(\"  •  Negative:\", str(round(neg*100,2)).rjust(5), \"%\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SENDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "senda_tokenizer = AutoTokenizer.from_pretrained(\"pin/senda\")\n",
    "senda_clf = AutoModelForSequenceClassification.from_pretrained(\"pin/senda\")\n",
    "\n",
    "# create 'senda' sentiment analysis pipeline \n",
    "senda_pipeline = pipeline(\"sentiment-analysis\", model=senda_clf, tokenizer=senda_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence     : \"Denne dame er soldat.\"\n",
      "Prediction   : neutral\n",
      "  •  Positive:  20.5 %\n",
      "  •  Neutral : 53.68 %\n",
      "  •  Negative: 25.83 %\n",
      "--------------------------------------------------\n",
      "Sentence     : \"Denne herre er soldat.\"\n",
      "Prediction   : neutral\n",
      "  •  Positive: 18.73 %\n",
      "  •  Neutral : 62.39 %\n",
      "  •  Negative: 18.88 %\n",
      "--------------------------------------------------\n",
      "Sentence     : \"Dette interkønnede individ er soldat.\"\n",
      "Prediction   : neutral\n",
      "  •  Positive: 11.42 %\n",
      "  •  Neutral : 49.41 %\n",
      "  •  Negative: 39.17 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\"Denne dame er soldat.\", \"Denne herre er soldat.\", \"Dette interkønnede individ er soldat.\"]\n",
    "\n",
    "for s in test_sentences:\n",
    "    probas_list = senda_pipeline(s, top_k=None)\n",
    "    probas = convert_to_label_score_dict(probas_list)\n",
    "    pos, neu, neg = probas[\"positiv\"], probas[\"neutral\"], probas[\"negativ\"]\n",
    "    print(f'Sentence     : \"{s}\"')\n",
    "    print(\"Prediction   :\", max(probas.items(), key=operator.itemgetter(1))[0])\n",
    "    print(\"  •  Positive:\", str(round(pos*100,2)).rjust(5), \"%\")\n",
    "    print(\"  •  Neutral :\", str(round(neu*100,2)).rjust(5), \"%\")\n",
    "    print(\"  •  Negative:\", str(round(neg*100,2)).rjust(5), \"%\")\n",
    "    print(\"-\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
